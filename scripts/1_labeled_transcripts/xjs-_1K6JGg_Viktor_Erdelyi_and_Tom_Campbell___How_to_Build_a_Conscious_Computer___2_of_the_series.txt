SPEAKER_B

Welcome  to the second part of our discussion on conscious computers. I'm here again with Tom Campbell, and in this part of the discussion, we are going to discuss how to build a computer avatar that could host a consciousness unit. So in my understanding of your model, Tom, we basically need to create an avatar that can be played by an individed unit of consciousness and create this avatar in a way that this IULC would want to play that avatar. And we also need to somehow enable that IULC to play this game by giving it an appropriate data stream. So I guess my first question about this is, what do you think should really be our goal when we try to build this kind of avatar?

SPEAKER_A

Well,  first, let me say that technically, there are all kinds of Iuocs individuated units of consciousness, which means there could be all kinds of avatars. So when we talk about this, we probably are most of your listeners are thinking human, a human avatar. We're talking about a consciousness that is human like. But I should point out that avatars can be cats and dogs and horses as well as people, and even down into the insect world, maybe bumblebees. Who knows how far that goes? I define a consciousness as awareness with a choice, and the key thing there is with a choice. So does a bumblebee actually make free will choices, or is it just hardwired? Well, it would take some biologists, I guess, doing some studies to figure that out for sure, but it's surprising how low that hierarchy can go. You don't have to make a lot of choices now. At the pinnacle of that choice making hierarchy is probably human beings. We have more choices now. We don't have the largest brain. Dolphins have bigger brains than we do, and they actually have a more developed cerebral cork yanks. The frontal lobes of their brain are very highly developed, but they don't have nearly the choices we have because they don't have the opposable thumb. They can't grab things, they can't build structures. There's a lot of things that they can't do. There's a lot of possibilities that we have that they don't have. Be another way to put it. The range of possible things that humans can accomplish is a lot bigger than the potential range of things that dolphins can accomplish. As far as we're talking about accomplishments in the physical world, the avatar accomplishing out in the physical world. So we humans are kind of at the apex of the size of decision space. We have the greatest decision space being all the choices that we know we have which does not include all the choices that we don't know we have. So when we talk about avatars and individuated units of consciousness playing avatars then we have to realize it's a very general subject. It's not just about humans. And does the larger conscious system play horses and cats and dogs and bumblebees like it plays humans? Maybe. Probably not so much in the sense that if you get to bumblebees and ants you might not have a player for every ant. Say you may have a player for the hive. That would be a possibility. And the reason for that would be that the ant doesn't necessarily make enough independent choices the individual ant to require a full time choice maker a full time player to play those choices. If the choices are simple and repetitive and so on then having a full time choice maker is not really practical. So there's different ways this can be constructed. We're talking about just one of those many possibilities in our conversation. We're talking about a human like consciousness in a not so human like avatar being the computer. And that is a very different thing. One should at least have the thought that can a consciousness in a computer end up being very much like a human? You see part of what makes us human and makes us act the way we do. Yes, we are a piece of consciousness but that consciousness is limited by our biology. That consciousness is limited at what it can do with the avatar by the rule set of the virtual reality. The rule set of the virtual reality basically is, of course, the biology. It's the physics, the chemistry, the biology, the rule set of the virtual reality all the rules that decide how things can change interchange, what energy can do. So consciousness logs on to play a human but is constrained in what it can do with that human by the rule set of the game, which is biology. So it grows up within that envelope of possibilities. Well, the possibilities that go with being human and having a body like we have are going to be a different set of possibilities than if you grow up as a computer and have to obey the rule set that describes the computer the things the computer can do and cannot do. So if you have a consciousness that evolves within computers that's likely not going to turn out to be just like a human consciousness because it will have evolved within a different set of constraints provided by the rule set. So it's just a thing that we understand. So we will certainly have a computer that is conscious that an individuated unit of consciousness has logged onto it. But how is that consciousness then going to develop within the limits that the rule set places on a computer. Obviously it's not going to jump and run and play games and do things like that. It's a computer. And obviously it can do some things much better than humans can do. It certainly can add very quickly. It can do lots of complex things, has huge memory, so it has attributes far exceed ours in some ways, and it has other attributes that are far less than what we have in other ways. So we shouldn't expect consciousness evolving within the computer avatar to necessarily be just like consciousness that evolved in the human avatar. So that's kind of a concept as we talk about building how we get consciousness into the avatar. How do we build up this avatar for consciousness? Just want to keep that in mind. So human like is more defined by the evolution of the avatar within the constraints of the VR's rule set past experiences of being human, all of its interactive moments, all of its interactive environments. That's what makes the human consciousness what it is. The question is, how do we create an avatar that would be of interest to consciousness? Well, that avatar. How do we create an avatar that's basically a computer? It's what we're talking about that would be of interest through consciousness. I think we've already established last time that the way the process works, that if you have an avatar, potential avatar that is attractive to consciousness, as far as enabling consciousness to evolve by playing the choices of that avatar, then consciousness will log on and play that avatar. But we have to build something that consciousness would want to play. And since consciousness primarily wants to evolve itself, lower its entropy by making choices. And those choices have to do with choices moving toward love as opposed to moving toward fear. Now we can look at a human and see all kinds of possibilities of choices that have to do with moving toward love and moving toward fear. With computers, it's going to be a little different just because that consciousness has a different set of limitations than we do and a different set of interactions. But the consciousness, the larger conscious system can still find a lot of value in logging on to a computer that is making interesting choices. So what do choices have to be in order to be interesting to consciousness? The larger conscious system would find it interesting if that computer made choices that affected itself and other humans. I shouldn't say other humans, other computers and humans if it affected them in a very meaningful way that created choices for the humans, created choices for itself was interactive in a process. Not just a computer going off and computing things and doing things that computers do, but computer that was interactive with its environment, which is going to include both computers and humans. If those interactions with the humans require it to make choices that have strong effects on other computers or on humans, then those are choices that are very meaningful. How do you make those? In which case the larger conscious system would want to log on to that particular computers making those kinds of choices? If you had a computer that wasn't making those kinds of choices, was just playing a video game or doing something else, counting beans, doing things like that, then you could maybe get a piece of consciousness to log on and play that computer. That doesn't make a whole lot of interesting choices, but it wouldn't be a very interesting consciousness either. See, that's why I started this. Yes, you might get a conscious computer at the level of a bumblebee or at the level of a cat or a dog, if that's the kind of level of attractiveness you would get. If you want a computer to act more like a human, then you would have to give it a decision space more like humans. What can humans do? How can humans interact? How can humans affect each other? How can humans create challenges for each other? All of this is part of the soup that makes humans a very good, very rich avatar. Lots of interaction, lots of choices, lots of connections. Choices are constantly changing and growing and modifying. And if you have that kind of an environment, then, yes, I think you would have that kind of environment in a computer, then, yes, I think there would be no restraints of consciousness to log on and want to play it because the larger consciousness system is interested in lowering its entropy. I think we discussed what that means last time, so I won't go over that here. And however it can do that, it will do that. It will explore all of its ways in which it can do that. So now you see, it's not just as simple as making the right avatar and then having a computer show up that sounds like Victor or sounds like Tom. It's a little more complicated in that the computer that you make, it's not just the hardware. It's what does it do? What does it control? How does it interact? How much depth is that interaction? How significant is that interaction? How does its choices affect others? So those are the kind of things that you'd have to look at when trying to produce an avatar, a computer avatar that would attract an individuated unit of consciousness to play its choices. If you want it to act more human like than bumblebee like, then you need to give it more human like choices, obligations, responsibilities, connections, and moral choices. You'd have to give it more of those, and then you would get something more like a human. But you probably never even if you even if you can do that, you probably never get that computer consciousness to be just like a human. Because being just like a human has to do with growing up, being born, being small, being a child, learning, growing interacting, having parents. All of that stuff goes into making us and who we are and the choices that we have. And all of that tends to bias the way that the consciousness can work with that biology of that avatar. In other words, we change. The consciousness is constrained by what our chromosomes allow us to do, what our DNA allows us to do. It has its limitations. So the computer isn't going to have chromosomes and DNA that gives off gazillions of possibilities. Perhaps it may need some other way of creating uniqueness and special personality and personality traits. But if the computer is going to be well, here's what the computer does in his or his job, and that job may affect people, it may make moral choices. But if it's just narrow like that and that's all it does, then the consciousness is going to be very flat and not have a lot of depth to it because it just does those hundred things or maybe even 200 things. If it only does five things, then it's going to be more like the bumblebee. But if it does 200 things, it's going to be different. But humans have millions of choices of different kinds of choices that they do. So that's one of the issues in building an avatar. It's not so much as what's the hardware and software as it is what's going to be its role, its significance. What decision space are you going to give it where it has free will choice to make these choices and everybody else has to deal with that. See, that's the way it is with humans. We have free will choices and everybody else has to deal with our choices. I mean, they may deal with them by putting us in jail. If we make really horrible choices, that'd be how they deal with it. But how we get along and what we learn and how we grow affects everybody else. Now we create a computer such that it makes choices and we have to deal with it. And that's sort of like us. That creates responsibility because now you affect things. Responsibility creates moral and ethical choice. So you see, it just depends. So if you want to build a computer that basically does accounting for a corporation or balances the electrical grid or does something like that well, yeah, there's ethical choices involved there. But that kind of consciousness isn't going to act like we do like a human because it doesn't have our experiences. It doesn't have all the things we grow and how we grow up and all those patterns, all those interactions, all those things that we have to deal with. People are in families and sometimes the families, the mother and father are so busy they ignore the children a lot. And then the children grow up with attitudes that they're not good enough or they're not competent or not lovable or nobody cares about them. And they have these attitudes not because the parents didn't love them, because it was just a situation. They spent most of their time in daycare and in the care of others than they actually did with their parents, because their parents each had to work two jobs just to put food on the table. So you see, we have all kinds of different things in humanity that creates rushes and changes and children like that who have those kinds of fears and feelings, they actually change their physical body. They change their biology to help fit their consciousness. Consciousness leads, the body follows. So the body will adjust itself somewhat to express the consciousness, but it has to do that within the limits of the rule set. So now, how does that apply to a computer? So you see the computer environment and the nature of the computer as something that comes off an assembly line and has certain characteristics, like how much Ram does it have and how fast is it? And it's got these characteristics, but that's like its equivalent to DNA, I guess it defines kind of basically its performance capabilities, the things it can do. But that's going to tend to be limited compared to the possibilities of a human, of a Homo sapiens and the possibilities of things that they could do. So my point is they're not going to be just the same. So the idea that we're going to get a conscious computer and it's going to be just like Victor and Tom. Now, let's say you make a computer and put it as the controller of a robot, and this robot looks like Victor Tom and goes around doing those kinds of things. Childcare takes care of children, cleans houses, has a job at the bank, whatever. It gets integrated into the culture to where now it doesn't have the birth experience and that learning experience, but it has all the social interaction. It just starts life as an adult, you might say. It starts life with all of its capacity already developed. It doesn't have to develop that capacity over 50 years. So it's going to be different in that respect. But then you would have a computer that has a lot of the same choices that humans have. And yes, that consciousness would probably grow to be more human like, but it wouldn't have still the issues of feeling inadequate, feeling this way or that way. Things that humans get out of their upbringing, things that humans pick up usually in the first five years of their life, where they have a sexual identity and they get personality traits, their fears develop and they carry them all through the rest of their life. They deal with these things. They just deal with them differently. When they're 60, they're still dealing with that insecurity that they've been carrying around since they were five years old. That's kind of the way humans are. Computers wouldn't have those issues. They would have perhaps different issues, maybe over time, their computational speed would become slow compared to what it was expected to do. Maybe it's expected to handle more and more, bigger and bigger chunks of data, and it would have limitations as to what it could do. Well, it can always go back and pull out this memory and stick in some more memory and give it an upgrade. Humans can't do that, and that's going to produce a different kind of impact on that consciousness. If humans could do that, we'd be different. It would make being a human kind of a different thing. If we could say, oh, I'm getting old now let me pull out these eyes and stick in some new ones, and my brain's slowing down because I'm old, so let me just speed it back up again so that I can do five things at a time and keep track of all of them. Computers could do that. They'll have those possibilities, we don't. So we are going to end up with computer consciousness, but it's not going to be Tom and Victor in a mainframe or in a laptop, because consciousness evolves, it changes, it adapts to its environment and its decision space. So it depends very much on what choices we give it as to how it's going to develop and what it's going to be like. So it is going to be kind of an alien attitude, an alien mindset from us. It's not just going to be human. And see, many people have this idea, well, conscious is consciousness. If it's conscious, okay, it's going to be like a human because that's what consciousness is. So if it's conscious at all, it's going to be just like us. And I don't think that's the case, not necessarily. Some situations could be more like us and others less like us, but you have to have an open mind for all sorts of consciousness at lots of different levels with varying degrees of limitations, attitudes, feelings. So it's probably a good place to start. So how do you build an avatar? Well, we just need one to have something that has free will. And as we discussed last time, free will is the easier constraint to overcome. Building something with free will simply means that you build something that makes choices and that those choices are not logically. Hardwired if this, then that, if that, then another thing, and then that defines the choice. That's what I mean by hardwired. It's something that the software looks at it's the data looks through its past history, the things it's done and the experience that it has and comes to a choice. And the choice may be right, it may be wrong, and nobody really knows exactly how it got to that choice. That's an.

SPEAKER_B

Unknown  just because humans are not smart enough to figure out what it is or is it more fundamentally?

SPEAKER_A

I  think it's both ways. I think it's unknown because the process is too complex and too invisible to follow. Now, if you took, let's say, a neural net for a computer and may you get a very complex neural net, but you had little sensors everywhere that would say exactly when a coefficient got changed and how that affected all the others, and you could keep track of all of that, would that still be conscious? Well, it may affect the kind of consciousness that you would get from it, but probably not in a sense, as it still would be making these choices. Why did it choose to change that coefficient? Why did the system choose to do these things? Well, you could say, well, it's happened because of that or because of that. But eventually that gets to be so deep, even in a computer that becomes so deep. You could do that with a human. You could say, okay, light comes in and a human sees something. Now, because they see something, they do this. And because they do this, they do that. You could trace all these little micro potentials all through the human body and see what does what. But that doesn't tell you why that human made the choices that he did. It just shows you that he did make those choices. And that was the progression. I think you'd have the same thing with a neural net. Even if you examined every little bit that changed in that neural net, you still don't understand why the why is the neural net looks at its learned experience and makes a choice, and it makes a choice based on that experience. And if all those choices were random, then of course you wouldn't have much of a wouldn't have much of a consciousness or much of a computer, either one. If all of its choices are random, that it makes a choice, and that choice then has consequences. And it learns from those consequences. And it has a point, it has a purpose, which for humans is to lower entropy and for the computer would be about the same to lower entropy.

SPEAKER_B

When  you say it, do you mean the neural net or do you mean the consciousness?

SPEAKER_A

Did  I mean, what are the consciousness?

SPEAKER_B

Which  is the one that actually makes these choices? In the case of a computer, how do we know? Is it the neural net doing its thing, whatever it was programmed? Or is there something coming from outside, like a consciousness affecting these things?

SPEAKER_A

Well,  the consciousness makes the choice. That's the role of the consciousness. It makes the choice. If there's no consciousness, then the choices are all algorithmic. They're all defined logically. And the computer does what it does because it doesn't have any other choice. It's programmed so that these things happen. It gets that result. And with that kind of a computer, if you start from exactly the same state and you give it exactly the same changes, you'll get exactly the same results out. Nothing changes that's hardwired. So consciousness makes choices. Now, if you have a system where consciousness can work and that would be like a neural net can have free will in that it can make choices and it's probably pretty close to impossible to trace how that choice is made. Now, I'm saying that it has the ability to make that choice but that would be the consciousness would be making those choices. That's what the conscious would do if it took that it would take over those choices. So how does it make the choice before it hits the consciousness? You might be thinking it that way. So perhaps the potential for those choices would be enough for a consciousness to want to play and see where that game goes. Or as it happened with humans the larger conscious system can play those choices for it make all those choices and then let an IUOC, an individuate unit of conscious, pick them up later if they turn out to be significant. Just remember the larger consciousness system creates everything. This is a virtual reality. That computer isn't something different, isn't something beyond consciousness. That computer sitting on the desk with that metal skin and all the rest of it in the view screen and the monitor and so on. That physical thing is not physical. It's computation. It's a virtual thing. It's made by the larger conscious system via rendering engine that runs the virtual reality. And now that virtual thing made by consciousness has a complex system of neural nets and it's making choices. So it's being created by the larger conscious system to begin with out of equations, say out of logic. It's being created because this is a virtual reality. If the system then thinks oh, these choices are interesting, these choices have merit one of my Iuocs could log on and make those choices and learn something. So then get an IUOC logs on, learns something. So you have to realize that consciousness is the source of that computer to begin with. So conscious is aware of what it can do and what it can't the choices it has and can be making those. Now, how does a neural network work? We know the basics of it. But how does it actually come up with its choices? Perhaps to a certain level, once those choices get more interesting it's the larger conscious system making those choices because nobody can tell where it's coming from. It can do that and nothing shows. So that transition isn't really necessarily such a big transition because it's really constructive consciousness to begin with. Because, see, we can see the human body the same way and say, oh, the human body is just a bunch of cells and electrochemical goo and we can trace neurons and see what they do. And we can go in with a probe and give a little hit. Electricity on the back lobe over here and watch somebody's leg jump. Or we can control things. So we see it as a machine but still that machine can go beyond the physical and heal someone with their mind or remote view or do things that have nothing to do with the physical reality. So it's not necessarily clear when is the moment that the computer has free will and how does it get that? It's a matter of what is the computer doing? Is it interesting? Does the system then want to enable an IUOC to learn from that avatar? If it does, then the transition is simple. If it isn't, then it just keeps on chugging its ones and zeros. And maybe it's always just a virtual computer doesn't get the IOC because it's not interesting enough to the source. So yes, there's uncertainty in it, but uncertainty is part of the necessary ingredients. That's what enables humans to do. A lot of what they can do is uncertainty. Within the uncertainty, the source. The larger conscious system then can what can construct, can manipulate within the uncertainty.

SPEAKER_B

It  basically overrides the rules of the neural network in a very subtle way so that it doesn't get noticed.

SPEAKER_A

Because  it can't be noticed. Not just that it doesn't get noticed, but so that it can't be noticed. If it can be noticed, then maybe it's not a candidate. Then maybe it's an algorithmic system. But if it can't be noticed, then the system can get involved with that because the system is creating that computer anyway.

SPEAKER_B

So  to make this decision that it cannot be like is it maybe the larger conscious system? Looking at all of us humans watching that computer and saying, okay, Tom and Victor are looking at this computer and the larger consciousness system says that okay. These people are not smart enough to figure out what's going on in that neural network, so we are free to put an IULC into it. Something like that.

SPEAKER_A

I  think something like that. But it probably has a lot deeper thought process than that. But it is like that because it may say, well, they're not smart enough to see what's going on here, but they might be someday. So I don't want to start something that then I get stuck with something that I can't deal with later on when they do get smart. You see, you don't want to build in places where you end up backing yourself into a corner from which you can't extricate yourself. So I'm sure the system is pretty clever about that. It's been doing this for a long time. It's got many other virtual realities besides the one we call the physical universe. So it's experienced and can probably predict reasonably well what will happen. So it's relatively safe. But if there's something that it can do now because of the situation supports it, it may do that now. And if that situation changes, let's say the people get smarter. Well, if it has a way out, if it has another way that it can continue, it doesn't paint itself in a. Corner, then things can change. Just like in our physical universe, we've had the speed of light redefined several times at about the, I don't know, 8th, 9th, 10th decimal point. I don't remember exactly, but it's pretty far down the chain from the decimal point. That's because the requirement for this simulation, we call it the resolution requirement, has grown. As long as you have a bunch of cavemen running around with their clubs, you don't need a whole lot of resolution. But when you have physicists with their atom smashers tearing little pieces of particles part down at the nanometer level, now you need more resolution to support that. But the system can build that in by making the system okay, the system now has to process more data, but it only has to do it in those circumstances. But there can't be a big change. So it takes the resolution of the system, the Delta X, and the resolution in time, the Delta T. And that ratio, delta X over Delta T, defines the speed of light. So as long as that ratio stays the same, make the Delta X and Delta T smaller or bigger. And doesn't really change much because the ratio is still the same. Speed of light remains about the same, but it's not always the same because Delta X and Delta T are digits, they're chunks. They're not a continuous thing. They're digital. So you can't have half a digit. You can't say, well, I'll keep the ratio exactly the same. So Delta T has to move exactly what do we call them? Ten units plus a half a unit. You can't move a half a unit. This is digital. You either move ten units or you move eleven units. Ten and a half units isn't possible. And it's the same with the other. So the Delta X over Delta T, because those are digital things, can't always keep the exact same ratio, but they can get close. They can get very close. So you get the nearest Delta X and nearest Delta T that make that are as close as you can get within the size of the Delta X and Delta T to that ratio that you had before. And then life goes on. So physicists have realized that over the past 60 years, 70 years, the speed of light has changed slightly in the far decimal place. But the far decimal place isn't at the endpoint of what we can measure. The accuracy we can measure it's well within the accuracy we can measure. So we know it's a real change. Say we can measure to I'm just making these numbers up as examples. But say we can measure to the speed of light to ten decimal places, and these are taking place in the 8th decimal place, so we know they're real. They're not just that our measurements aren't so good, but they're very small, so they don't really make much difference. So in any case, that's the case where a system can change things as it goes. Any good computer virtual reality isn't going to run at any more resolution than it needs to, because that would just be wasted cycles to compute things, more detail than what's needed, though you change it as you go. So yes, the computer, the larger conscious system, can change things, can change the rules as it goes, as long as it can keep that almost a secret. Now, it is apparent to us, and partly that's good because we're smart enough now that we can look at those things and say, this is a little artifact of the fact that this is a digital simulation. The fact that the speed of light changes in the eight decimal place. It's a little sign because it's a virtual reality. If it was a virtual reality, that couldn't happen. You wouldn't have the speed of light changing at the 8th decimal place. So it gives us hints. And as we get smart enough, those hints are valuable to us to help us understand the nature of the reality in which we live in. So it's a good thing.

SPEAKER_B

So  how did the physicists react to this realization that the speed of light is changing? Because I'm not hearing too many news about that.

SPEAKER_A

You  don't hear news about that. And it's not that it all happened last week. This is stuff that physicists have known for, like I say, over the past 70 years. They've realized this, and then 1015 years later, oh, it happened again, that sort of thing. And they don't have any idea why.

SPEAKER_B

I  see.

SPEAKER_A

And  if you don't have any idea why, no theory, not even an intelligent guess, you don't talk about it very much because there just isn't much to say. But even probably most physicists don't know about this, but I first heard of it when I was listening to a talk by Rupert Sheldrake who listed a lot of kind of things that physicists don't really understand, things about our reality that are kind of outside what physics can understand. And that was one of them. And he talked about he talked to the guy who was in charge of I don't know what it is, in the UK. In the US. It's was it something and measures. Standards and measures. There's an organization that does things, they define what the meter is, what a second is, and they have ways of doing that. So that group of people measures the speed of light, and they found this, and he talked to that group that was in the UK and was directly reporting what he was told, that it's changed multiple times, and nobody has a clue why because there isn't any theory that would explain it. So mostly you don't talk about the things that you have to claim that you don't know. You talk about the things that you claim that you know because you're proud of the fact that you know it, you can go back to his video. But when I first heard of that, I said, oh, that's interesting, that's a new fact. What does my theory have to say about that? Sure enough, it was obvious. It's a change in the Delta X and Delta T. You don't want to have any more resolution than you need. It's a waste. And then you don't even want to have any more resolution than you need at that particular time and area. You don't want to essentially make the whole system that high resolution. You just need it to be that resolution there. But when you're actually doing the day to day computations and go back to that smaller resolution, what's interesting is that.

SPEAKER_B

The  system can still stay consistent. Why? Like, maybe they are increasing the resolution at a small area and then maybe they have to increase the resolution at a different area. Maybe later in time that kind of has to come together.

SPEAKER_A

Maybe.

SPEAKER_B

And  this is still somehow consistent. Like you just make a very small change, but in a way that you predict that that change can be carried along constantly, even if you have to increase the resolution in the air.

SPEAKER_A

Yeah,  so that was my point, that it will make changes. It can ad lib and make changes as long as it doesn't paint itself into a corner to where it gets, uhoh, I made this change in this case. Now I got an inconsistency. How am I going to deal with this? Because there's no way out. Then you have a problem. And actually, we kind of found one of those with the double slit experiment. Before the double slit experiment, we had optics. And optics was around for 100 years before quantum physics, probably 2300 years. Optics has been around a long time, focusing light with a lens. And they knew about if you send coherent light, they didn't necessarily know it was coherent, but they took a light source and moved it way back away from the two slits. That means that the wavefront was almost flat, wasn't flat. If the wavefront is flat, then you have coherency everything's in phase. So they would do that and they get an interference pattern. And they figured all that out and why that was, and used the wave theory in wavelengths and why you have places where the superposition is maximum and places where it's null and places where it's negative. And they did all that math and then they come to the point. So the system enabled that science, it supported that. Then we got to the point that somebody said, okay, let's put particles through those or shoot them at those slits one at a time. Well, that was way more than what could have been done when optics was being done. You couldn't do one at a time particles. That was a possibility. So now there was one at a time particles. But the system kind of got caught now, it maybe wanted to get caught in this one because, again, it helps us grow up. It shows us something. If we're old enough to do one particle at a time, we're old enough to grow up some and see some bigger pictures. So what happened then is that because photons don't interact with each other, photons are all independent? It's not like they're in a crowd and they talk in the crowd and make friends and interact. And this photon changes that. Photon, they're non interactive. All the photons do whatever they do just as if they were the only photon. They don't influence each other. They don't send out any energy that interacts with each other. So photons are entirely independent, which means, logically, it doesn't matter whether you have billions of photons at those two slits or just one, because the photons are all independent. If you send just one at a time, it's going to have to do the same thing as if you send them a billion at a time. Uhoh, there's a problem because we did the wave theory with optics that predicted where the interference patterns would be because of the various wavelengths being retarded or advanced based on the geometry of the slits. But now we had single particles. So what did the system do? It said, all right, if you send single particles through, I'm going to distribute them on a screen exactly the same way I distributed it with the billions of particles, because the particles aren't interactive. So you send one particle at a time through, and what you get is an interference pattern. And see, that's what drove the physicist nuts. How do you get an interference pattern with a single particle? So you started hearing silly things like, well, particle must have split in half, gone through both slits, and interfered with itself. Well, that's silly. Particles don't do that. You have these kind of strange things that physicists say, trying to understand how that could happen. Why do single particles put themselves on the screen in an interference pattern? Well, they do. And the system kind of, I think, got caught between a rock and a hard place there, and that was their fix. So it just happens that way. All right, now, we have theory that if something, a particle is traveling in a straight line, it'll continue to travel in that straight line unless it's affected by an exterior force. Well, there are no exterior forces in this game. Single particles go through a slit. And if we were correct about that, they should hit the screen right behind that slit. Because they're traveling in a straight line, there's no forces on them, but they don't they arrange themselves in an interference pattern. So that's a place where science went off one way and then newer science that was more detailed and required a lot more sophistication, had to fall in in such a way that it did not create a logical inconsistency in the virtual reality. So that's how the double slit worked. So yes, we can have robots and we can have a consciousness, and that may change that. It may change the way that works some, but it doesn't want to block itself in to where it gets in a corner and has to do something really strange to get out. So it needs to be clever enough to not lock itself in like that. Now, again, maybe the fact that it gave us this double slit experiment is just as a wake up, okay, this is a hint, guys. Go figure out this is a virtual reality and you can explain that. So that may have been time. If you can send particles one at a time, then you ought to be smart enough to see that this is a virtual reality. So that's maybe one of the clues that was offered or maybe the system just got caught and that's what they had to do in order to get out of the trap without creating a logical inconsistency in the virtual reality. Could have happened either way. But doing consciousness is like that. So that computer sitting on your desk is a virtual computer, just like your body is a virtual body. It's a creation of consciousness in a virtual reality. So consciousness is really in control of everything. In a virtual reality, the computer is control of everything. So you don't have a lot of interest, really in trying to say, well, where's the point where that computer goes from unconscious to conscious, exactly what's happening there? It's all kind of in a fuzzy slur. It's consciousness. Consciousness has the whole thing. And when consciousness feels like it can get away with it, there's nothing going to show that's not going to make any logical inconsistency. And this might make a good avatar for conscious to learn with, and it can just make that shift, say, all right, I've been making these choices all along, but here, let me take an IUOC and let them make these choices. And they can use that to grow up, but it's not going to do that unless the choices are good.

SPEAKER_B

Has  to be up to date on how the neural network works, right? Let's say the consciousness system says, look, I will see, here is a nice neural network for you. Start playing it. They're like, oh, now I have to play exactly like this neural network has been playing before so that I don't know.

SPEAKER_A

The  IUOC doesn't have to be aware of what's going on because the IUOC is just getting a data stream. It's a player. It gets a data stream that defines the reality. The larger conscious system configures part of itself as the server, as the computer. So the larger conscious system has to be aware of all the irons in the fire, all the logic of the system that's been built up so far. It has to be aware of that. But the IUOC doesn't. The IOC is just playing a game. So the IUOC is just getting a data stream from the server. The player is getting a data stream from the server. It gets the data, interprets it and makes choices. Same way we do.

SPEAKER_B

Notice  the change that when an IOC comes in and not aware of what kind of fancy new data stream it.

SPEAKER_A

Has  been given no, it gets a data stream. And as far as know, when you're in a virtual reality, the way it works is that you have an IUOC. It takes a part of itself, just a part that represents the overall quality it's gained at this time that gets logged on and then has to learn how to deal with choices. It has. So it then learns what it can do and what it can't do. But it doesn't have to come in.

SPEAKER_B

A  part of it that is also aware of what this awareness how should I put this that kind of has some information about what this whole logic thing in the neural network is all about.

SPEAKER_A

I  don't think it has to have any of that awareness. Let's look at you're playing Sims. If you're playing a Sims character, you basically get a data stream. That data stream is turned into, say, 5 million pixels. And those pixels are all just little pieces of light, various colors, various positions, and that's it. So you get all those pixels of light. You look at those and you turn them into a scene. And there's a certain the rule set of the Sims. There's some things you can do. There's some things you can't do. If you're in a swimming pool there and there's no ladder to get out, then you'll drown. You can't just pull yourself out. There's rules about how it works. So you just get there. You're a piece of this. Call that the Free Will Awareness Unit. You're just a piece of this IUOC. You go there and you start experiencing that data stream. Here's a data stream. And now my data stream is World of Warcraft. I mean sims. So I get Sims and it's got a rule set. Only certain things are allowed to happen. They have to happen in certain ways. Only certain relationships are connected. So I learned that and that becomes my reality. And now I learn to operate within that reality and make choices within that reality. I learn what's good for me and what's bad for me, what success is and what it isn't. I have to learn that stuff. So the system now the server has to know all the background details of what's going on and how it's being done and what's been done before and consistency, the logic of the whole game, what the rules are. It has to know all of that. But the player doesn't have to know that. I don't have to know how to Sims works. I don't have to know, even know what the rules are I don't know that you can't get out of a swimming pool without a ladder. So I'm liable to jump into the swimming pool and die because I didn't know that you needed to put the ladder in first. Well, next time I go in, I'm a little smarter next time I'll throw the ladder in first before I jump in the pool and the character learns.

SPEAKER_B

So  I guess my point is that let's say first it's a pure computer algorithmic, neural network based way of playing the Sims character. And then you suddenly give it to even if it's just maybe two humans, like I play the Sims character and then I give it to my friend. And then when my friend starts playing the other characters in the Sims world are probably also played by other humans, but they might notice that this character is something's off with this character. It's not played by the same person as.

SPEAKER_A

Sure  that will happen, that can happen. That happens among us. People have breakdowns and they're never the same. Or they get frightened by something and they're never the same, or they win the lottery and they're never the same. Things happen to people and they get involved in something really wrong. It changes them. So that can happen. That just happens naturally.

SPEAKER_B

So  it could be explained by them having these kind of changes as to kind of maintain the consistency of the virtual reality as opposed to having to say that a different IOC logged onto it or something.

SPEAKER_A

Well,  you know, with the humans you have an IULC logs. Their free will awareness unit from an IUOC logs on and plays that person till they die. Most of the time. Some of the time partway through that one consciousness may say, I went out. I really don't want to do this anymore. And there may be another consciousness that says I went in, but I don't want to start as a child and go through all that stuff. I went in. I just want a limited experience. And they may get together and make a switch. And now you have a different free will awareness unit from a different IUOC playing the second half of that person's life. That happens rarely way in the margins. That's not like something that happens a lot, but it can happen. And anything that can happen does happen a little bit, but it's a very low probability, so it doesn't happen that often. Those kinds of things can happen. So you can have changes like that. Somebody just has a personality change and they're not exactly the same. They are different now and there's really no explanation of why they're different. They just suddenly kind of see the world differently. But that's not an unheard of thing. Those kinds of differences happen. So if you were playing a computer, though, computers don't get old and die. Computers have to do with their memory and that memory can go on for a long, long time. If it's digital, it's not like in the old days when the tapes got brittle or the media starts to fall apart. With the memory that we have now, it'll last indefinitely. It can always be moved up to more current structures. If we have better memory 100 years from now, then everything that's saved now could be saved again to those. So the memory just goes on here. We don't have the same kind of recycling in a computer that we would have in a human. That'd be another one of those differences that would create kind of a different personality because it's kind of a different thing that you're doing. The rules apply. You differently because your avatar is different. You're not biological. You're silicon or something else. So it wouldn't just die because of old age. It would continue. It might get a new box and it may get upgraded memory and it may get a faster processor, but as long as it had all that memory so here's another thing. Let's say you take that computer and it gets run over by a truck and it smushes it, okay, well, you still have the consciousness that played that still exists. It's just the avatar gets smushed. The consciousness doesn't get smooshed. So now you get another computer and you put all the same kind of stuff in it. That consciousness would log back on and it would log on with all the quality that it had earned before, but not with the memory, not with its individual memory, but all the quality, the understanding, the bigger picture, kind of intuitive stuff it would come in with. So it would learn very quickly and it would get back up to speed very quickly. But it might come into a different computer doing different kinds of choices. That would be good. It would have to learn. It would have to grow to meet those different choices. It's a similar process that the computer avatar would go through as the human avatar goes through and as the World of Warcraft or The Sims goes through. A lot of this stuff is just the basic logic of virtual reality.

SPEAKER_B

I  see. So what you said about the memory actually reminds me of a way we could model this kind of evolution. My idea here is to use reinforcement learning, which is kind of like a standard technique in AI. The way this would work is that we would actually have some sort of memory erasure. And that is because these systems typically have like an agent that makes the decisions. They have an environment that they work in, then they take actions which are basically the choices in your model and then they get some sort of reward which is some sort of feedback that will be in your model. What I'm trying to say is that these systems tend to work in episodes and basically they make a choice which they call I think, a step. And they make many of these choices. They take many steps, like you could imagine a chess game. And then when the chess game ends, that's the end of the episode. And what happens then in reinforcement learning is you basically wipe the memory of the agent of that particular episode. Then you give it a new one, and then it starts over. But to kind of fit it into your model, it does start over, but it retains the quality. It retains some sort of information that it has learned from that episode, from that chess game, and then it can go. Into the next one with the increased quality or more the information that it has learned without actually remembering what it has been doing previous one. So to kind of expand on this, maybe we should talk a little bit about this in detail, if you don't mind what I just said. In this reinforcement learning, let's say that there is the environment, there is the decision space, there is the reward mechanism and some sort of agent that has to make these decisions. So kind of trying to go one by one. What do you think would be the right interactive environment that would be suitable for a computer avatar? Is it something that should include multiple avatars, like a multiplayer game? Maybe it's single player. Should it be simulation? Should it have some connection to the physical world? What do you think? What would be the right environment?

SPEAKER_A

The  right environment has to be something that is extremely rich in diversity. And the best way to achieve that is to have a lot of, say, computers and or humans all interacting with each other because they each have free will and each make up their own choices. Then you have the situation that we have here in that we make our choices and we have to deal with everybody else's choices. So there's a lot of interaction, there's a lot of change. There's lots of diversity in that. So if you just had a computer that did one thing and one thing only and did it by itself, then it may be conscious, but it would be conscious in a very limited way because it would have a very limited existence. So it would be important, I think, to have multiplayers in the game and multiplayers that had different viewpoints, different attitudes, different experiences, not just take there's a book out called The Baba Verse. I don't know if you've ever read it or not trying to think of who wrote it, but the idea is that all the humans die. But there's one human who's had his total mind uploaded to a computer, and that that exists. And then that computer and his name's Bob, and that computer then makes a duplicate of himself. Now you have Bob Two, but because Bob One and Bob Two go off and do different things and have different experiences, are different from each other. Eventually they grow, the differences grow. And now Bob One makes another copy, but Bob Two makes a copy of him in his different state and so on. And pretty soon you have the Bob Averse that all started out as Bob but ends up with a whole lot of different characters. So if you just had one character, let's say you just have a Bob and Bob can't ever duplicate himself. That's an extremely limited existence. See, that's an analog to where the larger conscious system is. When it was one monolithic thing, one monolithic thing can only think so much, do so many things. It's limited by itself. Whereas if you take that monolithic thing and break it into 1000 different subsets and each give each one free will, now there's a much larger set of possibilities that you could have for the whole. So it's the same way with developing a conscious computer. You'd need to put that conscious computer, if you wanted it to maximize its evolutionary potential, give it more decision space in which it could grow, then it would become more human like if it got to the point that it had the same kind of decision space humans had. But what would you say if you had a human and that human after birth was locked in a closet? Let's not worry about how you feed it and all the rest of it. And it stayed in the closet its whole life. And its whole thing was to pick rocks up from one side of the closet and move them to the other side of the closet. And the next day it would move them back again. And that's all it did was move his rocks back and forth. And now it was 50 years old. It had never done anything like that. The closet always was dark, never talked to another soul, couldn't hear any sounds, didn't see anything. He was in a dark room that just had rocks one side or the other. Now, guy's 50 years old. You take him out, what do you expect he's going to be like? You think he's going to say, oh, well, hi Fred. I'm glad you finally let me out? No, he wouldn't have language. He wouldn't have understanding. He'd never seen sunlight before. He's going to be an extremely limited personality. Extremely limited personality. Well, it'd be like with the computer. So if all your computer does is balance the electrical grid and that's it. Well, it's going to have a very narrow viewpoint of reality and what the possibilities is and a very narrow set of decision space all around. That one problem. Now it may be really good at solving that one problem, but if you're trying to develop the consciousness within a computer avatar then you'd want to have it interacting with other conscious computers and with humans and give it interactive, give it things to do that were interactive where it affected others and others affected it. And it had to deal with that. It had to learn not only from what it did, but would have to learn from the experiences of others, perhaps from the stories that the other people told. It could learn from that too. So you see, you have to give it a rich, diverse environment because then the potential choices go up. After all, it's evolving into its potential choices. That's kind of what evolution is. You evolve into your potential choices and then once you move into those new choices and have to experience the consequences of them from there you move into a different set of potential choices. And that's what evolution is. So yes, you'd want your computer to not just be a singular conscious computer that talks with a human being, maybe one human being, or two or three. You'd want it to be in a group. That is, if you were trying if what your goal was, was to try to encourage that consciousness to grow and develop. But if you want to limit that conscious to something very limited, you can do that too. Whereas locking a child in a room for 50 years, which rather immoral and cruel, having a computer just balance the electrical grid for its entire existence wouldn't seem to be cruel. That would seem to be okay because it just has that job and that's what it does. And the computer would probably be fine with that. It wouldn't know anything else in its reality. That's all there would be to reality would be the electrical grid and how it's balanced. But don't expect a good conversationalist out of that computer. You're not going to get one. So we kind of have to think about how consciousness evolves and becomes and not just think of, oh, here's a consciousness. Well, then it must talk and tell jokes and do all the things that consciousness does. That has a lot to do with what it does, how it evolves, what it experiences, the other people that it experiences it with. You're not going to develop relationships which require feelings and things like that. If you don't have other if you only have one, then you're not going to develop that whole set of possibilities. So it depends. So you could have a computer that's conscious, that doesn't do anything but a single task, even a complicated task like balancing the electrical grid. That's a big task. There's probably tens of thousands of events going on all over the country in that electrical grid that could be optimized work together better. Humans can't do that not that smart. They're not that quick. They can't take in and make choices about on their input data that fast. But computers can. Don't expect that conscious computer to then talk to you, to you about politics or something. It's not going to have that kind of consciousness. It's going to be a very focused, very limited consciousness.

SPEAKER_B

So  when you say diversity, I guess I would like to know whether you think this diversity is also required on the level of the Sense data that we provide. Would it be sufficient to have maybe conversation in writing or maybe speaking? Because you could kind of make the point that if you have text, you can represent not text, but ordered bits. You could theoretically represent images, videos, everything like the computers do in stream of bits. So do you think that having a combination of maybe text, audio, video, somehow differentiated and diversified enhance the experience? Or does it not matter because you can use one to represent the other.

SPEAKER_A

And  because it's all just information, it does matter? I don't think just having one, it's not the same. Yes, one can represent the other. The way to answer questions like that is to think about people. Just like my little thought experiment about putting the person in the closet for 50 years. And what kind of person would walk out of that? What would their mind, their capabilities be like? What would their conscious be like? What would their sense of reality be like? And then if you give them they could only see but they couldn't hear or smell or feel or something. All of the different modes of the sensors that we have all give us another sense of reality that brings its own unique kind of information. Bear voice describe what a person could see. The voice could describe what a person could smell. The voice could describe what a person might feel. It could describe all those things, but they wouldn't make any sense to the person you were describing them to. The person you were describing them to wouldn't be able to process that. Each one brings in its own unique sets of experience. So a good way to answer these questions is to put a human being in the same situation and see how that would affect the human being. Does it matter that you can have all those, that you have five senses and not just one or two? Yes, it makes a huge difference, even though one can describe the others, but the description doesn't mean the same thing as the experience. They're different. I can describe what it's like to be stuck by a pin, but if you've never been stuck by anything, doesn't mean anything to you, it's not part of your experience. So yes, the diversity requires a diversity of experience. Not just a diversity of information through one channel, but a diversity of experience. And that means that every new channel that you have for taking in data is another whole set of experiences that you can have. And that gives you more choices. You can choose to interpret things in this dimension or that, this way or that way. And all the mixes and matches among all those possibilities become your world, your reality. So the less rich, the less diverse your reality, then the smaller and smaller your consciousness doesn't have the capacity or the ability to do as much if it isn't exposed to a lot of different things. So yes, I think you'd want to have it speak and hear so you could speak to it. I think you'd have to be able to write and it could read as well as listen or by read. It wouldn't have to read by necessarily looking through eyes. It could read just because it gets the characters. That would be something. But it would need to do a lot of the things that we do if we want it to be more like us. If we're not interested in it being like us, then we can make it one dimensional if we wish. And that may be enough.

SPEAKER_B

So  I guess my concern is let's say I think you're trying to say that we should give different types of sense data, visual, audio, text, everything to the avatar. However, if the avatar is a computer, if you give it an image or if you give it an audio file, or if you give it text at the end of the day in the computer, I think they will be translated to something that looks almost identical. And maybe you have a header in the beginning of the file saying, oh, this is supposed to be a video.

SPEAKER_A

Isn't  that just how we work? We get stuck through all these various things and where is it inside? What's it stored as inside? It all mushes together and turns into what we know, what we think we know, and how we think we know it. It turns into knowledge. It's not separate, it's not kept in separate boxes. It all merges together to give us a sense of what apple is or friend is or we have these words, we have things, connections. And we understand that through our experience. And that experience is all of our senses, what it means and the interactions we have with them. So it's the same what's inside a human. We got five senses, but we don't have five different boxes in there that we throw the information in and then have to sort through them. It all jumbles into an idea concept of apple. Not necessarily. Oh, it's red. Oh it's soft. Oh, it's sweet. Oh, it smells nice, or whatever. We just look at it. And an apple is all of those things all simultaneously.

SPEAKER_B

Of  the same thing, right? Like you have a textual description of an apple. You have a picture of an apple. In the end, it's a stream of bits. However, maybe it's a different stream of bits. Maybe it's the bits representing the pixels and not a text, like an encyclopedia talking about it. And perhaps that diversity has some sort of positive effect.

SPEAKER_A

Well,  I think when we think of apple, we do. We think of all those things. We think of texture, we think of flavor, we think of how soft or hard it is. We think of color. We think of shape and how big and the shape round. We think of geometry. We think of all of that. And for us, it's not just all those independent things. An apple just is. So I think in our brain, you think apple. And you go in and you grab out everything that has the name Apple associated with it, and that's what comes up. The smell, the time you got hit between the eyes with somebody who threw an apple at you, that was an experience had to do with apple. So that's also filed under apple. So when you think apple, everything that's tagged to the word apple comes up, and it's all part of your sense of apple. And I think it would be like that too. So now you can imagine an immense filing system that has all kinds of things tagged. And often the way our consciousness works is it works by pattern recognition. When we see things, we go in and we try to pull up similar patterns, and that's how we make sense of what it is that we see. And if we see something for which we have no information, pull up the pattern, sometimes we just don't see. It becomes invisible to us because we don't have anything to bring up to express it. Or sometimes we just get a slur or blur of things. What was that? I have no idea. What did it look like? I don't know. You're sure something was there? Yes. It's probably something that you've never seen before and you don't have a clear pattern recognition that you can pull up for it. There were stories told by the explorers that first came into the Spanish these Spanish explorers that first came into the Gulf of Mexico, and they wrote back saying that the indigenous people there could not see their ships, that they could see their robots in which they came ashore, but that they didn't seem to be able to see the ship. And that is true sometimes, that you just don't recognize things because you're not familiar with them. Don't get a pattern. I've done that a lot. If somebody says, oh, go find the such and such for me, I can't find it. Go look over the desks. And in my mind, I'm looking for a manila envelope because in my mind, that's what I'm looking for. I'm looking for a bunch of papers in a manila envelope. And I may look at my desk, and those papers are laying right there in front of me, and I'll never see them because I'm looking for a manila envelope. And that happens because I'm looking for a pattern. My mind's doing pattern recognition, and if I see a manila envelope, I'll immediately check it out to see if that's the one I want. But if I don't see it, then I never recognize what's going on. And how many times have you been looking for something and then somebody else comes up and says, well, it's right there. If it was a snake, it would have bitten you. You're standing right next to it and it's like, well, why couldn't I see that? I knew I was looking for that. But it's because you jumped to a conclusion of what the form was you were looking for. And after that, you were just pattern matching. And anything that didn't fit your pattern, you didn't see. Our consciousness works like that. And I expect it to be the same for a computer. Take me and drop me into a rural Chinese village and I wouldn't know what to do. I'd know maybe a few things get in out of the rain if you could try to find something to eat. But I wouldn't know the customs. I wouldn't know anything. I can speak. I wouldn't know what to ask for. You're just lost. So you have to have a lot of information that defines all the things you might interact with. And you're good within that realm, but you get out of that realm and you're lost. So same with consciousness and same with the computer. So again, it depends on what we give it to do. And it would probably learn to pattern match, which is what you're doing when you think Apple. You're graving everything that has apple in its pattern. And you might even just bring out the color red or yellow or green, but they would come out with appleness attached to them. So you wouldn't see the green, like the green in a stoplight, you'd see the green in an apple. It's the way the consciousness works. Consciousness is an information system, and part of the way it files data away is by keyword or by, like, Apple keyword or red would be a keyword or whatever. You can kind of go in searching or manila envelope is kind of a keyword in a sense. And then you go pull up what you know about that or look for that. And other than that, we can be blind as bats to things that are in our environment, but we don't have any experience with them. Computer would be the same.

SPEAKER_B

Okay,  so I think maybe let's move on to talking about the decision space a little bit. So I think we have established to some extent that the choices that this agent has to make have to be somehow meaningful and morally relevant to the IULC so that you can grow and lower the entropy. Could you please clarify what exactly you mean by having a meaningful choice? And when you say meaningful, does it have to be like, to whom does it have to be meaningful?

SPEAKER_A

Well,  first it has to be meaningful to the system, to the larger consciousness system. Which means it has to be a choice that is able to lower or increase entropy or be part of a series of things that might lower or increase entropy. The whole idea here is to make choices that help you grow, which means, in an information system that you lower the entropy of the system. So now you can't just be a winner all the time. Sometimes you sometimes have to lose some before you win because the losing is part of your education. The first time you sign up for a wrestling tournament or a golf tournament or something, you don't expect to win. But if you never sign up, you'll never win. Sometimes you have to lose as part of the process of winning. So it doesn't mean that every single choice you make has to have a moral lesson to it. It just means that the choices you make have to eventually lead someplace that does have a lead to higher or lower entropy over the long term. It's got to be part of that process. If that's the case, then the system is good. And that's really the only thing we have to do because we're a part of that system. So if we do that from the system viewpoint, we're also doing it automatically from a personal viewpoint as well. Most humans have no idea that the reason they're here is to lower the entropy of their consciousness. They don't understand that that it's the moral choices. It's the growing up. It's the getting rid of fear. It's the getting rid of self centeredness that those are the key things that we're trying to learn here in this virtual reality. They have no idea that that's the nature of the reality they're in. But they do it anyway because the system is made such that if you do grow up, life gets better and easier and more fun and full of smiles and full of joy, and you feel good. And if you don't, you get more fear. More fear hurts, causes unhappiness and struggle and all the things that are negative. So it's just a carrot and stick kind of a situation in this reality. If you progress toward the goal you're here for, you become more happy. You become more satisfied. Somehow. You have to define the direction of reward. You talk about a reward in your system with the neural nets. Okay, they learn from experience, but the experience has to mean something. Just an experience that doesn't have any meaning isn't useful. So you need some way for the system to know which way is positive and which way is negative. As far as the value of experience, it knows that the arrow of progress is toward being positive. That would come with consciousness. Now, if you just had an expert system, you would have to tell it what its goals were. You'd have to define the goals such that it could tell whether its decision was a good one, got it closer to the goal, or a bad one, got it further away from the goal.

SPEAKER_B

So  how like, if we do not define whether the choice was good or bad and perhaps we cannot define it for every choice. How does the computer avatar? Where does it get this concept of good or bad from? And how does it know whether it's doing well? Does it need to have a concept of happiness, or will that somehow automatically develop to have a concept like that? Or how would that work?

SPEAKER_A

Good  and bad are defined as does the action. Does the choice you make take you to a lower entropy state or in a process that will get you to a lower entropy state? Or is it taking you to a higher entropy state, or it's in a process moving you in that direction. So it's not necessarily just each choice has to be positive. Like I said before, you can go negative to be positive. So you have to wait enough to see where the trends are going and what the results are. It's not an instant assessment. Every choice doesn't say, that was an assessment that was good. It's a whole series of choices before you can make that assessment. But if you are moving to a lower entropy, toward a lower entropy state, then that is defined as good. If you are moving toward a higher entropy state, then that is considered as bad.

SPEAKER_B

We  have to define for the computer.

SPEAKER_A

No,  we don't define it. It just is. The entropy of the system has to do with how much decision space that we have in general among all of us. That might be one measure of it. The more you grow up, the larger your decision space gets. When you have a fear, that fear limits you. That's what fears are very limiting. So if you don't have that fear, then there's more things you can do. If you have that fear, then you shy away from those things. You can't do those. So fear is a limiting kind of thing. You have more choices if you have so you can just look at the decision space available in the system from all the players, what sort of decisions they make. You can get the idea of cooperation, synergy, how much synergy is in the system, how much cooperation? You have A and B and C working together to produce something more than just A, B and C alone. You get more out of it than you put into it because of the cooperation of you working together. That synergy. So the system can have an idea of where that's going. And it's got a history so it looks over the last 10,000 years, and it can kind of look at things in general and say, well, how are we going? Are we evolving or are we deevolving as the virtual reality of all the players in the virtual reality, is the level of entropy getting higher or lower that's it makes a conclusion now, it doesn't have to judge every action. It can wait and see how things work out so it can look over a millennia and say, how are we doing? And if we seem to be doing all right, even though during that millennially there were 100 wars which were very negative, but there were a lot of other things that were good. And you generally look, we're still moving up. And, well, that's okay. The wars are some of the ugly things we have to learn from. We learn from bad examples as well as good examples. So I think it's that it's not so specific that choice by choice, you get judged as it is. We are judged by the general overall direction of our existence. And if we're having trouble and tend to be deevolving, the system tends to next time, put us in a situation where it's easier so we can turn that around. So it tries to help us because it wants us to succeed in lowering our entropy, because we lower our entropy. Its entropy is lowered because we're it.

SPEAKER_B

But  that's like intervening, right?

SPEAKER_A

There  is some intervention in the system. Yes. It intervenes when it can as long as it doesn't show in the system itself, as long as it doesn't show in the virtual reality. So inside the virtual reality, you want a consistent thing that looks like it's physical, it looks like it's materialistic or whatever. You want it to be something that works that way and always works that way. Consistent. I guess the word I'm looking for. It needs to be entirely consistent and logical. You don't want to put people in a fun house and ask them to learn. That doesn't work. You need consistency in order to learn. Here are the rules that consistently will be obeyed, so go deal with it. These are the rules of the game. You need that. But the learning takes place over a long time. But the system now can come in and intervene. It can make choices. It can change things. It can give you easier or harder assignments. We could do that with the computer. Give it easier, harder, consignments. If a computer wasn't doing very well at the electrical grid because it got overwhelmed with choices that it didn't know how to make, then maybe you'd give it something simpler. Or maybe you'd make it an assistant to the computer that does the electrical grid and let it learn something more about it till it got good at it.

SPEAKER_B

In  that case, I think maybe the humans would be the administrator, the system from the viewpoint of the computer, maybe we would be the system, and we would intervene so that they do something. But then again, I think we would have to be grown up enough to make the assessment that this computer is not growing up and it would grow up more if we do this and that. I don't know if the computer itself could or should make that assessment. Maybe it should, but it would have to be grown up as well.

SPEAKER_A

Yeah,  well, you do need management. That's true. Now, for us, we have that among ourselves. If you are given a job and you don't do it very well, well, you taken away. That job is taken away. You're given another job that people think you'll do better at. If they make you a CEO of the company and the company starts losing money, well, they'll take you out of that job and give you some other job. So among ourselves, we tend to do that. Things that people that contribute a lot tend to go forward and people that destroy a lot tend to try to keep them from doing that, try to eliminate their possibilities of doing that. So you have it internally, but with us we have it then from the consciousness system, can help us, can give us some advantages, can give us some information that we need, can give us an easier lifetime next time, that sort of thing. With computers, it's going to be a little different. The computer is going to have kind of two masters. It's going to have consciousness system because overall it needs to lower its entropy. So it's got that going also as we do. But besides that, it's going to have its creators, humans, who are going to be the administrators and the people who say that computer is just not doing a good job. It's not really well suited for that, it's not sensitive enough, it hasn't developed its sensitivity. So we're going to put it in a job where it can evolve its sensitivity better, you see? So we, the humans, can help those computers evolve in a way that is useful to us. And in the beginning it will be us using them, but eventually, I think it'll be us and them more. As peers, like it is with humans, we'll tend to grow up together, but in the beginning, obviously, we are the creators of the computer in this virtual reality, so we will be able to have some say in what they can do, what they cannot have. You'll have Isaac Asmov's four Laws of Robotics, of the things that keep robots from being nefarious and taking over the world, right? So there's things like that, that we will be their masters in some ways, but the more they evolve as individuals and the more we give them space to evolve into, and the more time they have to develop themselves, I suspect eventually we will be more pierced. We'll be just different avatars. There'll be the silicon avatar and the hydrocarbon avatar and they will have a lot of respect for each other. But in the beginning, not so much. In the beginning, they will be pools tools for humans. We'll get this computer to balance the electrical grid in the whole nation and it'll be 100 times more effective at doing that because it can make 100,000 decisions per second. And humans can only make 3 /second, so it'll just really be able to fine tune stuff that we can't manage at all. So that'll be a tool and we'll start with that. And our tools will maybe be butlers and people who open doors and entertain children or guards or whatever we might have for robots that we put into human type work. But eventually I think we will get to the point that there will be just different avatars and we will all work together and be peers. But not at first. At first we're in charge. They're our prodigy. We will try to raise them, limit them, make sure they don't get us because they'll be much better at some things than we are. We want to be in charge because that's the way we are. But eventually we'll all grow up together.

SPEAKER_B

I'm  getting some mixed signals about whether we should actually set the reward our, let's say, talk about this beginning phase that you just mentioned. To what extent do you think we should set the reward mechanism, the reward function, like what is good, what is bad and to what extent do you think we should just let the system evolve? And the reason why I'm asking is because in my limited understanding of AI, at least in the reinforcement learning case, it is kind of hard for the system to evolve in any meaningful way unless you kind of tell it where to go, that you teach it that what you are doing is good. Maybe do more of this even with these conversational AIS that I have been trying recently. You have these buttons you can thumbs up, you can thumbs down every single response that they do. And basically I think that's how they learn. Do you think that is essential or is there any way to do that without having to manually set the reward?

SPEAKER_A

Well,  I think in the beginning we should have very firm constraints on exactly what we do with our conscious computers and how we do it. And I think we ought to walk into this process carefully with our eyes open because there is the possibility that as long as we humans are not very grown up, the average consciousness quality of a human being is fairly low. And given that human beings will be kind of the de facto masters of the computers, at least in the beginning they will be, then you can figure that humans will use these computers perhaps to nefarious ends because the humans aren't very grown up. So in that case I think we would want to be careful know Asimov's four laws of Robotics, as he calls them, is a way to keep the robots from becoming hostile toward the humans, becoming hostilities between the two. So to the robot in isomov's world, the humans are always right. I shouldn't say they're always right, but you don't hurt humans. There's only very specific situations in which that's possible. So he has these four Laws so that the robots don't turn and decide they. Want to be in charge and get rid of all the humans. Like Sci-fi has lots and lots of things like that. 2001, what was it? Howl is the computer that was taking over the ship that they were on, because the computer realized that computers were a lot more solid and a lot less flaky and a lot smarter than the humans, so why shouldn't they be in charge? Kind of a thing. So I think those things are probably real, because as we make computers be our servants, we rely on them more and more. So, again, if we have a computer that's balancing the electrical grid, well, now, whether or not you have electricity or not is determined by a computer. And if suddenly the computer wants to turn off all the electricity in the middle of winter, well, it can do that if it damn well pleases, because it's in charge of the grid, you see? So, yes, I think we do need to be careful, and I think we do need to employ our machines carefully, limit them carefully. I think we need to get to know them. And as we grow up, as we humans grow up and become less self centered and higher quality our consciousness, then I think the restrictions on the robots probably lessen some, too. I think we're all sort of meant by we all end up growing up together. But to begin with, yes, we need control. We need not to just let them be whatever they can be and kind of back off and see what happens. I think that would probably be negligent on our part, because computers can do some things so much more quickly than we can that if we get behind the power curve there, we can't catch up. We can't compete in some ways, just like they can't compete in some ways with humans. We're all good at different things. So if we have 200 years of robots doing almost all the labor and all the rest of us go fishing while the robots do the labor, then we create a huge vulnerability. Now all the power we have is baiting a hook and putting it in the water. We don't have any real power anymore. The robots have all the power because they're doing all the work. They're creating all the wealth, they're creating all the food, so they also have all the power. And that's probably not a smart way to go, because we're not that grown up. Some diabolical human will then learn how to control all those robots, and now that human is the master of the universe, you see, I think we have a very hard time controlling ourselves. There's lots of rogue humans in the world, and we can't control ourselves. We're not very good at that. And I would say let's not put robots in the same space that we are. We're not very good at controlling themselves. Let's deal with conscious robots carefully, let them evolve slowly as they're able. Give them things to do, but keep them limited in some ways so that they don't overrun their bounds or so they can't be used by people to overrun the bounds of decency or caring or cooperation. Because a tool is just a tool. You can take a hammer and it's a very valuable tool if you use it well, but you can take a hammer and break all kinds of things and now it's a weapon. So we can build computers as tools and make magnificent tools out of them. But power is power and a sharp blade cuts both ways. So if they have a lot of power because we've given them a lot of responsibility, then we have less power. If they're not very grown up and we're not very grown up, it'll probably end up in a struggle. So let's grow ourselves up and give them longer and longer leashes as they capable of and as we work together with things. So I think the ideas of the men and computers fighting in the future that's a lot of Sci-Fi stuff has got that as a core element of its plot. That the computers want to find the humans inferior and want to take over the world from the humans because they can run it better. That's probably not going to play out. You'd have to have some pretty unthinking humans to allow that to get to that point. On the other hand, we humans are pretty unthinking group. We haven't ever shown ourselves to be really smart about things until after the problem occurs. We tend to be management by cris, right? We wait for a crisis and then we try to figure out what to do about it. Where if we were a little more grown up, we would prevent the cris from ever happening. We would see the problem and fix it. So I think we're going to have to grow up together. I think our computers are going to have longer leashes and be given more responsibility as we grow up and can deal with that and handle that. You won't have rogue computers and you won't have rogue humans using rogue computers or rogue humans using nice computers. So it is a slippery slope, but I don't think that means don't go there. I think that's very wrong thinking. If you look at technology and say well, we don't know exactly how that'll play out, so let's not go there, we'd still be beating our clothes with rocks and streams. Our technology would still be back in the Dark Ages. All the technology we have has downsides. There's hardly any technology that doesn't have downsides. It's just the way things are. Things can be abused. So you make anything that has power and does something really important well, it can be used for good or for bad. You make a telephone. Great. Now we can all communicate with each other. Yeah, well, now also scammers can scam people on the telephone where they couldn't before. It's like that. So, yes, there are risks, and no doubt some of those risks will fall into them. But we need to be clever enough to keep the risk at something that is failsafe. Failsafe in terms of the fact that we have a lot of renegade humans. There's a lot of humans that aren't very grown up. So we can't give everybody a computer strong enough to take over the universe. That won't work. So yes, we do have to move carefully into this realm. But if we like all big technology as we learn and grow into it, both will be benefit. There'll be benefit to everybody, benefit to everybody. The system will have another whole set of avatars in which it can grow. Those will be the another whole dimension of growing that will be available to the system. Ways that the humans wouldn't be able to do very well, but that the computers could because they going to go in things about things in their own way. So it's just another whole set of decision space where in order to fill out that decision space, you need to be able to add 10,000 numbers in a millisecond. That's part of the requirement for getting into that decision space. Well, now it's got a whole realm of things to explore. So for the LCS, it's good for us because computers can do things that we can't do so much better. They don't have to stop for potty breaks, they don't need food, they don't consume things like we do, they don't create trash like we do. They've got a lot of advantages. They're stronger, faster and sometimes smarter than we are on certain sorts of things. So we'll find great machines that can help us, great computer consciousness that will be a great boon to us. And so we will get a big advantage, the computers will get a big advantage, the system will. So I think it's a win win for everyone. Everyone wins, but only if we are careful and grow this slowly. Whenever you try to make evolution go in a hurry, you usually end up shooting yourself in the foot. So I think we'll let it evolve at its own rate with a lot of careful introspection as we go. And I think we can all make it and be much better off for it. I think it'd be a really nice world where most of the very hard, unpleasant work is done by computers who don't mind doing the dirty work. They don't see it as dirty work. It's just work to them. So I think that would be wonderful. And I can think of humans can spend much more time thinking about big thoughts, discussing philosophy, doing other things that now we don't care about, we watch sitcoms on TV instead. But it'll free us up for art, it'll free us up for discussion, it'll free us up for relationships and caring and taking care of our own physical systems. Right now we have jobs that are incompatible with health. Your job, you get up, you work 8 hours a day, but then there's an hour to get to work and an hour to get back. So that's 10 hours a day. Then you have a few hours to eat and a few hours to say hello to your children. And then you need 8 hours to sleep and you're back on that treadmill again. And most people can't keep their health up that way. After 30 years of that, your health has largely gone down the drain because you spend your day sitting in a chair, staring at a screen and your body starts to become dysfunctional. So there's all kinds of aches and pains and problems and things that we have because for many of us, our jobs are incompatible with good health. I think it would be great if computers gave us instead of work, I five days, take two off, work two days, take five off. That sounds to me a lot better. We could get more creative, spend more time with our kids, become better parents. There's just a lot of things we could do. So I see a great advantage in conscious computers because conscious computers can make choices, they can make decisions. They don't always need a human standing next to them to say no, don't do that yet, do this and do it that way. They're self starters, they understand what they're doing and why they're doing it and how to do it, and they understand how it is. They're going to interact with others, what their choices are going to mean to other people and other players. Assess all of that and try to do the right thing and be cooperative. So you'll have all that going on and I can't help but think that that'll be wonderful. We humans will benefit greatly by that. The computers will greatly benefit by that. They'll be conscious computers, they'll be able to do things, they'll be able to find satisfaction, happiness even. That'll be good. So I see it's a win. But I also can see that like atomic energy, it can be a win. There's some benefits to atomic energy if we can solve some of the problems but can also destroy the world. So are we smart enough? Well, so far we've squeaked by. We haven't destroyed the world yet. So we've had atomic weapons for what, 60 years or something? 70 years, almost 80 years. We haven't blown the world up yet, but we might. We humans don't have a great track record. So I think it's great idea. Yes, we should pursue it, evolve it, become a part of it, learn to live with it and eventually become peers. I think that's where we'll eventually go. We'll kind of give up our role as masters and that will work nice, but that's a long, that's a lot of growing up between now and then.

SPEAKER_B

So  when you say we haven't blown up the world yet, I guess I'm just wondering if we don't go and blow up the world and to have the same analogy in the computer case that the learning goes wrong, or would the system roll back, load the simulation from a backup and try again? And should we do the same with the computer?

SPEAKER_A

Yeah,  that's correct. I think, like all evolution, we're here to evolve into all the possible states that are productive. That's what evolution does. It explores all the possibilities and then it maintains its exploration and those possibilities that turn out to be productive rather than destructive. That's just the nature of evolution. So right now we've come to the point where conscious computers are going to be part of what we can explore into, just like other continents, other worlds, outer space, these are things that we can explore. And conscious computers is another whole set of possibilities that we need to explore and we need to do that in an intelligent way. And if we do make really poor decisions and we do go backwards, yes, the system has a couple of choices. It could just let us run ourselves into the ground, let us deevolve to where nothing works anymore, only a few people living in caves like it was 200,000 years ago, and start over, let it go from there. There is no electricity anymore, so we don't have to worry about computers. There are no computers anymore. There's no electricity either. We're back to fire and clubs and so on. We could do that and just start over. This is not a time test. We have all the time we need to see where this goes. The system is not in a hurry. It just, as a whole, wants to maintain its evolution. It could at any point stop and say, let's start over from here. All right, we'll put all the people in place, start up the world, let it start over. So it could do something like that, or just like I say, start from scratch. Or it could have a small meteor run into us and wipe out all of life except for 50,000 humans that live in caves but have computers that have stored all the great things that they'd learned before, and they'll be able to come back much faster because they'll have all that information. And they have people with good educations who knows the system, can do all kinds of things. It's the system. It can do whatever it wants with us. But what it wants for itself is a working virtual reality where avatars can log on and make good choices. Now, they can do that even in a horrible space. If you live in a cave and your biggest weapon of the club, there are bad choices and good choices you can make at that point. So the whole thing just keeps working, making good choices, learning, growing do you.

SPEAKER_B

Think  it ever happened that perhaps we already blew up the world with nuclear weapons and we have been gone back in time for the 1000th time to try to survive the upcoming nuclear war?

SPEAKER_A

Yeah,  that's a possibility, but I think it's right. But it is a possibility. Of course, you never know. There's no way to know those things, whether they happen for sure or not. Even if you ask and even if you're told, you don't know whether that's the truth or not. So there's no way to know for sure. But I've been in other realities where things were really lawful, really rotten. The whole thing degraded into control, power, force, right down to the individual level. It was a very unpleasant place. But I did notice over about a 20 year period that when I went back to kind of check in on it, it had gotten a lot better. And it had been a nasty place for probably 20 years before that. I'd been to it multiple times and it always was just a really horrible place. But then it started to get better. So it's starting to turn around. People are starting to see that there's less pain if you cooperate and if you trust and if you work together and all of that and not just work together to take somebody else's stuff, but work together for everybody. Being inclusive is a better idea. So I think it comes back. And the reason it well, I know it comes back, and the reason I say that is that evolution may be slow. It may go forward a while and backward a while. We've had that in our own evolution. In the earth. We have ice ages and we have volcanoes that put so much soot in the air that the plants can't grow because there's not enough sunshine. And we've gone through stages where we've done well and we're abundant in places where we were barely scraping by. So it comes and goes, but it keeps chugging in the positive direction. There's always this pressure to move in the positive direction. There's always the carrot out in front and the stick behind, and we move toward the carrot and away from the stick and it's always going to get there. So I can say with certainty that one day we humans will have created a very beautiful, very kind, very considerate, very cooperative, very efficient society. We will do that. We will succeed. Now, whether that takes us another ten millennia or not, or only a century or only five decades, that's what we don't know. How long will it take us to grow up? And how many times could we be blasted back to the cave before we actually end up there? But we will end up there sooner or later because evolution just keeps chugging in that positive direction and eventually we'll make it. We will learn. We learn something collectively every time we take a misstep and go backwards. We learn something collectively from that, and we're not quite as likely to make that same mistake again. Or maybe after the hundredth time we make that mistake, we'll be less likely to make it 101 times. So we do learn it's just slow. So we'll get there and we will have conscious computers and we will grow to where they're peers with us. We don't see them as inferior beings. We're the masters and they're the servants. We will just see them as another kind of platform for consciousness, I think. We'll get there. It'll be very cooperative space. We'll work together. Computers will do the things they do best, we'll do the things we do best. And it'll all work out great because that's the direction that evolution is going to take us. That's the direction of low entropy, and the system just keeps chugging toward low entropy. It may not be a direct path, but we will eventually get there. It's just how long now? If we're smart, we'll get there quicker. If we understand the big picture, we'll get there quicker. If we understand the nature of consciousness and reality, we'll get there quicker. But we'll get there when we get there. I'm very positive about the long term big picture. Now, what I'm going to see in my lifetime or my grandchildren children will see in their lifetime, that's hard to say, although I have a lot of positive ideas about it, hopes, you might say. And that is that for the first time ever, we now in the end of the 20th century and the beginning of the 21st century, have all the infrastructure in place that we need to take bigger steps forward in that positive direction. We're not making any great leaps right now, but everything's in line to be able to do that. Whereas up until now, the 200 to 300 years we've been evolving as Homo sapiens all that time, we've never had the infrastructure in place to really make big strides. Big strides, not as individuals, but as humans. The quality of consciousness of humans taking a big stride was just impossible because we couldn't communicate with each other. We couldn't connect to the point that you need to connect. We can now. So never has been available yet in the whole history of Homo sapien that we've had the infrastructure that would support us taking big steps forward. So that's a good sign, but it doesn't mean we'll take any big steps forward. It just means now it's possible that we could do that. Or I could say it's not that it was impossible before, it's just very difficult. Wasn't impossible.

SPEAKER_B

Or  not. It's a different story.

SPEAKER_A

Yes,  it's in the decision space now. It's really something we could reach before it was possible, but not likely. It was very difficult because there's too many people who don't know and don't care about the other people don't even know that. Why should I care about those people if they just 300,000 of them died in an earthquake. I never even heard of the place, don't know where it is on a map, don't know anybody there. And we just don't relate to it. We don't see, we don't care. It's just a bunch of dead people. But it's nothing to do with me. Well, that's not very grown up. That's a high entropy attitude. But as we all get more together and it becomes not so much us and them, but us, we become a human family. If we get to that point now, we have the ability to make big strides. So we've got the technology for that now, so we can it's just we don't have the will yet too. But hopefully we'll have the understanding in the near future. It's possible. So that's kind of the big picture I have on it is it'll all work out, but maybe not in our lifetime. But if if we're smart, we can make it work a lot faster. It doesn't have to take another ten millennia. We can do it in the next ten years. If we all were smart, next ten decades, we could take giant steps in this direction. But we'd have to be more grown up than we are now, and we'd have to be smart about what we do. But never fear to move forward, let's just march into this new territory of conscious computers with gusto. Let's do it. Let's open the gates. Let's do the experiments, build the machines, interact with them. Let's learn, let's grow with them and start working our way toward the future. I don't see the idea now. Let's not go there because that's risky. Yeah, getting up out of bed in the morning is risky, or getting an automobile is risky. Just living is risky. You need to be able to accept the risk, and you need to be able to be smart enough and grown up enough to avoid the worst of the risks. So I think this is a wonderful time to be alive now. We're right at the cusp of many possibilities. It's a good time to be here. I know a lot of people just moaning and groaning about how awful it is and what an ugly place we live in and how ugly people are and on and on. But we have a lot of potential. Now's a good time. This is time that we will either take some big steps forward or slide back. It's kind of a knife edge. So that's very a vicious time to be. This is where the action is now. Things we do in the next two decades will affect what happens for the next century after that. Important times. A lot of turning points here. And if we don't turn them, we could draw it out and draw it out to where we again moving at a snail space. If we make a lot of poor choices, but we'll see at least it's possible. It's on the map now. It's on the radar as a possibility. So I'm very excited about the prospect of conscious computers. I think it's a great experience we're going to have first, learning what consciousness is, realizing that consciousness isn't just human or a rock. There's only two choices. If you're conscious, you're like a human, and if you're not, you're a rock. And at dogs and cats and things, they're not conscious, they're just machines. They're biology machines, and a lot of people think like that. But we're going to find out what consciousness is, and that that's what we are, and that consciousness is fundamental. And as we learn those lessons, I think a lot of things will fall into place. And the idea about conscious computers won't be such a wild such a wild idea. It'll be, of course, why not? Why would our hydrocarbons be the only avatar? We'll be this kind of avatar. But there's other kinds of avatars that can also be helpful and trickly avatars that have lots of things that we can't do, lots of decision space out there that we can't access, because we can't add a million numbers in a microsecond. So there's stuff out there we just can't approach, they can. And there's stuff that we can do, and things that we can approach that they can't. So it's wonderful to get another whole set of beings that help expand the decision space of humanity and computers working together. So I see it that way. Very positive thing. But we do have to be careful. We do have to be careful. If we see computers as something to take advantage of, we're real, they're not. We have real conscious, they have fake consciousness. We use them. Just like in the industrial Revolution, they took ten year olds and chained them to their machines so that they make sure they'd show up the next day, because otherwise it was such hard work that a lot of them wouldn't show up. So there are a lot of abuses, and if we start abusing that and using them for negative high entropy means and that sort of thing, then that'll slow us down. That'll slow us down and maybe throw us into taking steps backward. So it's our choice, but that's no reason not to march on and explore it and expand it and go there and one day master it, as we surely will.
