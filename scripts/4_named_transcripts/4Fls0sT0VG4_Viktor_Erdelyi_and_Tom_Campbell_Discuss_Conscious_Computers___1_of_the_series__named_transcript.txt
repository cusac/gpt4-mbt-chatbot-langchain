SPEAKER_B

Today  I'm here with Tom Campbell, and he is a physicist and consciousness researcher. In the past 40 50 years, he has been focused on scientifically exploring the properties, boundaries, and abilities of consciousness, and his findings are published in the My Big Toe Trilogy, which is MBT for short, where he proposes a model of reality based on the simulation hypothesis. This model provides a complete theory of consciousness. It explains our place and purpose in our reality, and also derives several existing scientific results, such as relativity and quantum mechanics, from a small set of initial assumptions. So about myself a little bit, who am I? I'm part of the MBT volunteer community, and my role here is to facilitate the conscious computer project. And the goal of this project is to explore the concept of silicon based consciousness inside computers, study the evolution of this type of consciousness, and use the results to evaluate Tom's MBT model. So what we will do here is I will be asking questions to Tom in order to give you an idea about how the MBT model approaches the concept of conscious computers and also to give the viewers a solid foundation for exploring this topic in more detail. So let's start by introducing some of the MBT concepts in the context of conscious computers. So I think what we should start with maybe is to define what consciousness actually is in your model and what are the main properties?

XXXTom CampbellXXX

Okay,  this is a good place to start. Consciousness, in a very short answer, is awareness with a choice. Now, I can expand that a little bit to see exactly what does that entail. Awareness implies memory. Memory implies the ability to learn free will. When we talk about free will, that means it has a choice. A choice implies free will, because if you have free will, then you have choices. If there is no free will, then there are no choices. So an awareness with a choice is the short term. Otherwise, you could say awareness, memory, free will, choice, and an ability to learn if you wanted to kind of put all those little subcategories in there. So awareness is basically awareness of what it's the input function it receives. Data is awareness. So it's something that receives data. It can remember that data. It can learn from that data, which means it's self changing. It's about information. So consciousness is an information system. What are you aware of? Well, what you're aware of is information, a description of something that you're aware of, that awareness is information. If you think about yourself, what are you aware of? What does your consciousness take in? What are you conscious of? And what you're conscious of is your sense data. You have five senses, and those senses are your what can we call them? Sensor platforms. They're your source of data. So you see and you hear and you smell and you taste and you touch. That gives you data. And then you process that data and come to conclusions about the real world based on that data. And what would you be if you took all that data away? So you can't feel anything, you can't see anything, can't hear anything, can't taste anything, can't smell anything. What would be left for you to be conscious of? Well, the only thing that you would be conscious of is that you were conscious. I am kind of the descar moment. I exist because I am, or I am because I think and I get in data. So there would be nothing. But you a piece of awareness, of self awareness kind of floating in a black void. So our consciousness, what we're aware of, is just information. Therefore, I model consciousness as an information system with those qualities.

SPEAKER_B

Okay?  So that takes care of the definition. And I think in your model, you seem to be saying that consciousness is one of the very fundamental blocks or building blocks of reality. So that kind of brings up the question, do you think that consciousness can be created, or is it something more fundamental?

XXXTom CampbellXXX

Consciousness  is the most fundamental of all things. It is the source. We start with consciousness, and from consciousness, everything else evolves. So consciousness is what is most fundamental. Matter of fact, it is the only thing that is fundamental. So maybe I should put it that way. So my model starts with an assumption of consciousness. Now, there are a couple of hand waving discussions we could have of where does that consciousness come from? What's the source of consciousness? Consciousness doesn't just appear out of nothing. That has to become what it is. But those models are all conjecture. There isn't any real solid description of where consciousness comes from. So basically, it's something like this, that you have things called cellular automata, which are very small pieces of code, little instruction sets. And if you keep repeating those instructions, in other words, if you have, like, a checkerboard and you say, well, everywhere that there is a black checker next to two red checkers, then that black checker will turn red, that's just a simple instruction set. And then everywhere on the board, that happens. And when that happens, then the board looks different. It changes things. And then you apply the rule again, and then that changes things, and you apply the rule again, and that changes things. That's the concept of a cellular automata, a simple rule that keeps iterating on itself over and over again. And you take that idea and you combine it with this idea that if you have a potential for something to happen, if you wait long enough, something will happen. It's another mathematical system, just like cellular automotive is right now, the name of it escapes me. But any case, then, that begs the question well, where did the potential come from? You see, and no one can really answer that other than well, there must have been this potential because here we are and we are conscious. Consciousness exists. So it's that we just don't know. Now that we don't know where consciousness comes from in a more fact based way is expected. We are consciousness. That's what we are. We are pieces of consciousness. And it's logically impossible for a thing to observe, to be able to observe in the first person its own beginning because you're not there to observe what hasn't happened yet, you see? So observing your own beginning is a logical impossibility. So because we are consciousness, we would have to get outside of this consciousness system in order to have direct awareness of the beginning of consciousness. Only something outside of consciousness can have observed the beginning of consciousness. So because we're inside consciousness, we always will draw a blank of exactly where did consciousness come from? So it's not that that's a failure of the model that it cannot tell us logically where consciousness comes from. It's just a reality of that we are consciousness and no system can get outside of itself. That's just the definition of a system it's contained, it's a set and you cannot get outside of that. So we just start with the assumption that consciousness exists. Not a terribly drastic assumption, since all of us, at least everybody listening to this will probably believe that they are conscious. That their awareness with a choice. Now, a few words about that. When you have a choice, that automatically brings in time because there's the before the choice and after the choice. So you cannot have a choice if there is no time. So consciousness, being awareness with a choice means that time exists also. And you also must have free will because without free will there is no choice. Everything is just fixed and nothing ever changes and there is no choice. So when we define consciousness as just existing, that's just an assumption. We're also assuming that time exists and free will exists. Those all are logically necessary for each other. Now, the opposite of that, the opposite philosophical corner is that consciousness does not exist, time does not exist and free will does not exist. And what you have then is materialism and determinism. So if you're a materialist, then you must, in order to be logical consistent, you also have to be a determinist because materialism is a deterministic concept. If you're a determinist, then it's basically the null set. There's nothing, there's no point, there's no purpose, there's no beginning, there's no end. There's basically nothing because there is no time. So there can be no change, there is no choice and there is no consciousness. So you can think of the null set or just blankness that has always existed and always well, that's basically determinism and that is also materialism. So that's kind of a zero philosophical position. Nothing happens, nothing can happen, nothing can be learned, nothing can evolve. And that's obviously not where we are. We do have awarenesses, we do evolve, things do change. So starting with an assumption of consciousness I think is probably the most rational assumption that we can start with given our everyday experience. Physics, science is about looking out, experiencing, seeing the world and then trying to explain it, not trying to deny it, which is what you would do if you end up in the materialist determinist camp. You'd look out, see the world and I'll try to figure out how to deny that any of it exists, which seems just a little backward and non functional and doesn't take you any place. So yes, that's the idea. Now, consciousness being fundamental, that means that know, Victor and Tom are both chunks of consciousness. We are individuated units of consciousness. And in my model, this consciousness system, which is, as I say, an information system has created for us to experience within a virtual reality. Because what is a virtual reality? It's just information with a rule set. That's how you create virtual realities. You have a server that serves up information to players and those players receive that information and interpret that information into reality, into what they're aware of. So that's how virtual reality, that's kind of a basic definition of what a virtual reality is. It's a reality created by information. And of course, if all the information is random and not associated with each other, then it's not a very interesting reality. So you have to have a rule set that defines the context with what can happen within the virtual reality. So here we are then individuated units of consciousness. We are players playing an avatar, a human avatar in this virtual reality game. So that's kind of a big leap. Now, there's a lot of discussion that we could have just on that point. We could fill up the next couple of hours just talking about that. But I wanted to just throw that out as an introduction because you have to understand that to understand something about the possibility and even the probability of conscious computers computer that's also conscious because we have now what appears to be in this virtual reality that we call the physical universe. We have what we call conscious humans. The human is the avatar. So it is an evolved avatar. We start with initial conditions and a rule set. Those initial conditions, as best we can tell, are what you're used to hearing about the Big Bang. So we start with the initial conditions in this computer of the computer being consciousness. The consciousness system is an information system. It can configure itself as a computer, configure part of itself as a computer. A computer is an information system as well. So consciousness takes part of its system, creates a computer, and in that computer, it creates a virtual reality. And it does that not by programming it, but by coming up with initial conditions. A ball of plasma very small, very small volume, very high temperature, very high pressure. And it comes up with a rule set, which is how that ball of plasma will change once you let it change. So then the run button is hit, that ball of plasma starts to expand and cool, and then you know the rest of the story. A universe forms like ours, and we form in that universe in our solar system, and people then form on this planet. And evolution then explains all the rest of it. So, in my model, that evolution is taking place in a computer, and it is defining this virtual reality that we call our physical reality. And it's done for the purpose of giving individuated units of consciousness experience. Now, experience is necessary because that's how we, as consciousness evolve, we have experiences. And by those experiences, we learn, we grow, we become different. That's how we learn. Now, experience that lowers the entropy of the system is good experience, and it creates positive evolution. The choices that we make that raise the entropy of the system that is deevolutionary and we deevolve our consciousness. Now, where does entropy come from? Well, all information systems survive by lowering entropy. If you have a set of bits and all the bits are random, then there is no information. Randomness carries no information. If you order those bits, you've created information. So when you order a couple of bits and you can give that order, that ordering. You can give it a name. You can give it a function. You can give it a definition that's creating, oh, see that little bit of order over there? That represents this. That then creates information. So in an information system, you create information by lowering entropy. Entropy is a measure of disorder. When all the bits are random, that's maximum disorder. As you order bits, then you lower the entropy of the system, you see? So consciousness evolves by lowering its entropy. Now, how does it do that? Well, it does that by the choices it makes. You can create entropy, which is raising the amount of entropy by making things more random, less information, making things less predictable. Or you can order things and lower entropy. So if you're an information system, you evolve. You move forward. You improve yourself by lowering entropy. And we are pieces of that system. We are just subsets of that information system called consciousness, you might think little pieces of it, subsets of it. What would be another way to say it? We're like virtual machines inside a bigger machine. If you think of an information system as a computer, then a virtual machine is just another smaller computer that's emulated by the big computer. It's called a virtual machine. So you can think of as a little computer created inside of a bigger computer, a subset of that bigger computer. So that's what we are, Victor. We are one of these little subsets of consciousness and we have all the attributes of the larger consciousness system, all that potentiality. But we just haven't developed that potentiality. And how do we develop it? We develop it by making good choices, by evolving. So in order to evolve, you need experience. In order to have choices, you need experience. In order to have experience, you need context in which that experience is defined. If there are no rules, then it offers you no experience. Lets us experience a game. All right, let's play the game. Go ahead. It's your turn. You see? Well, you can't do anything because there's no rules. A game is defined by rules. Now, if I define rules of the game, then suddenly we have strategy. We have ways that help us win, ways that help us lose. There's all sorts of things going on because there's rules. So by creating a virtual reality with a rule set and then having these individuated units of consciousness playing those characters, those avatars in that virtual reality, you give the pieces of consciousness experience by making choices within the limitations of a rule set. So that now is just a very quick overview of consciousness. But I know that sounds I've been talking for a long time here but that's kind of the basic concept that you need to understand to understand this idea of ours about what we're going to be talking about, about conscious computers. Because now, you see, it's not that you're a human. You're a piece of consciousness. And you are playing a human in a virtual reality. So the human is just an avatar. Well, if we have a computer and we're now asking how can that computer become conscious? Well, the same way that the avatar becomes conscious. If you can have a carbon based avatar like a human being, hydrogen and carbon based, then you could have a silicon based if that computer had the ability to make interesting choices. So you see, if you had a computer that had the ability to make interesting choices, then a piece of consciousness could log on to that computer as its avatar and then you would have a conscious computer. And that's the only way to get a conscious computer. As if the consciousness from the larger consciousness system, which is what is fundamental if a piece of that an IUOC individuate unit of consciousness decides that it can have experience with this silicon based avatar that would help it lower its entropy and evolve, then it would do that. Why not? It does that with these carbon hydrogen based avatars so why not with a silicon based avatar? The base of the avatar is not important. What's important is can a piece of consciousness lower its entropy through the experience and choices offered by a silicon based avatar? And of course it could. So you see, that's how you get a conscious computer. You cannot go out and just create consciousness. So I know, let's just put all these parts, all the software and hardware together in such a way that poof, we create consciousness. It doesn't work that way. You cannot create consciousness. Anything you create is going to have to follow the logic of what you've created. And consciousness does not follow a particular logic. Consciousness is creative. Consciousness can change. It makes free will choices. So you can't make awareness. You can't go out and build awareness. Now, you can emulate consciousness that way. You can maybe build a computer such that it can mimic a conscious being, but that does not make that computer conscious. Now, in a little bit we'll talk about that and compare that to what we'll call an expert system, which is something that has been made to emulate consciousness as opposed to a conscious computer as it goes to a human being and what are the differences and so on. So we'll talk about that later. But in any case, the answer to your question that you started with is that, yes, conscious computer is not only possible, but pretty much inevitable. I think we will see conscious computers probably within your lifetime, Victor, probably within the next couple of decades. It's not like that's far. Some like the antigravity belt of Buck Rogers. That's pretty far off. We're not going to see that if we ever see that. But Akaisi's computer is just around a bend. It's not that far away. In fact, there are computers right now that have consciousness, but at a very low level. See, consciousness isn't just like human consciousness. That's one form of consciousness, an individuated unit of conscious playing a human. But you can have an individuated unit of consciousness playing a dog or a cat or a bumblebee, anything that is conscious. Which means, like we say, it's awareness with a choice. That's all it takes. So awareness with a choice can be something that's very diminutive. It doesn't have a lot of choices. Maybe just two or three or four choices is all it has. But if it has any choices at all and it has self awareness and it can change itself according to those choices, then we call that conscious. It is a conscious thing. So consciousness comes in all sorts, from bumblebees to dogs and cats and horses to raccoons and foxes and human beings and monkeys and everything that we know as conscious things that have choices, that are able to have awareness, self awareness. So lots of things. So consciousness doesn't have to just be human. And we have computers now that do act like very low level consciousness. I remember that from many, many years ago. I think it was at MIT in one of their computer labs. They had created a little robot that acted very much like a bug. I think it was a spider. And it made those choices. If it came to a barrier, it would approach that barrier very much like a spider would. It reach out with a foot to see what was there, and then it would tend to explore that, and then it would decide what to do about it. So it had choices. It had various things it could do. And as you watch that little robot crawl around, it really reminded you of a spider because it moved like a spider. It did all the things that you would see a spider do. So that was probably a computer that had consciousness of a spider. So conscious computers have been around for decades, but at such a low level that nobody would call them conscious, because when we talk about consciousness, we tend to think human consciousness like a human. Well, we have not done that yet in a big way, but we may have be doing things that are very close, as we'll see later on in this discussion. There are some computers that do indeed act very humanlike in some limited ways. So I think we're approaching that. I don't know if we've actually created a conscious computer yet in the sense that it's similar to human, but we're getting closer. We're a long way from spiders now, and we're getting much closer to humans. And like I say, it's probably a matter of a decade or two at the most before we have a computer that is clearly conscious. And that brings up, of course, the question I know I'm jumping around a little bit here, but it just all seems to be organic. And that brings up the question of how do we tell whether a computer is conscious or not? And there is really no physical way to determine whether something's conscious. In other words, if we just look at it, talk to it, interact with it, there's always going to be some uncertainty. How does anyone prove that Victor is conscious, that Victor's not a robot or that Tom Campbell's not a robot? How do you prove just I guess you could dissect it and see what it's made of. But we're not talking about that. We're talking about from interacting with it, from connecting to it, from those kind of interactions. How do you tell? Well, you cannot tell with certainty. There's always some uncertainty as to whether anything is conscious or not, right? Because things make choices. Things have memory, things can learn. We have computers that do all those things, computers with memory, computers that can learn, computers that make choices, right? That's every day. Your desktop, your laptop does all of those things. But is it aware? You see, that's the point that's hard to determine. Yes, it does. All those things that consciousness that are part of the conscious definition except the awareness thing. And determining whether something is aware or not is not something you can do with certainty because awareness is entirely subjective. It's personal. It's not something that is physical. So you can't measure it. You can't go up and say, oh, here, let me take my awareness measurement tool and measure your awareness. Awareness is subjective, therefore, it's beyond physical measurement. So anything that's beyond physical measurement is something that we cannot prove with certainty that it is anyway. Which way? There's just no way you can't so we're stuck there. No one can come up with a test that determines whether something's conscious or not without some uncertainty to it. So you can't build consciousness from material parts because it requires awareness. And material parts don't come with awareness. They're unaware. So that is just a basic logical, philosophical fact that consciousness is not going to come about with a lot of peace parts that are physical. And that's true of us, too, in our carbon hydrogen avatars. So think of ourselves as a piece of consciousness, and we're playing a human in this virtual reality we call the physical universe. And the interesting thing, Victor, is if you make that assumption as wild and crazy as that sounds, if you make that assumption and say, well, okay, what are the logical ramifications of that assumption? And what you find is that just from that assumption, you can derive quantum physics from first principles. You can derive relativity from first principles. You can answer all of the paradoxes that are now in science, particularly in physics. Relativity has its own paradoxes. Why see a constant? And quantum physics has a paradox of why should particles be best described as probability distributions? And there's a lot of other paradoxes in physics. Where does time come from? Where does space come from? And lots of things that physicists just can't answer. And all of those answers become available from this model, from this idea that we're consciousness playing in a virtual reality. So it explains everything physical. It explains the entire objective universe. It explains all of objective reality, and it explains subjective reality as well. So now we have a model of the subjective world as well as a model of the objective world. And it's a much better model than the one we have now, which is materialism for the objective world. And we have no model for this objective world. So it answers all the things, all the questions, or it explains all the things we know about the objective world, and it also answers a lot of things we don't know that we will find out or that we right now can't explain. So though it seems like a wild kind of crazy idea that we're pieces of consciousness playing in a virtual reality game with a human avatar, that seems kind of outrageous. But if you just look at how well that model performs scientifically, then it performs a lot better than materialism or any other model. It's the best model we have as far as things like physics and chemistry and biology go. It explains all of the science much better than the materialist model. So anyway, we're giving an overview. I'm trying to give people some idea of what this thing is. Now, we're going to talk about conscious computers for the rest of this time, but that's just a little intro so you can understand where my answers are coming from.

SPEAKER_B

Yes.  So one thing that came to my mind that I would like to confirm based on what you said is when you say, when you talk about deciding whether a computer is conscious or some other entity is conscious, is it a binary yes no thing? And is it just our uncertainty that we do not know whether it is yes or no? Or is the consciousness itself also very gradual on many levels?

XXXTom CampbellXXX

Yeah,  well, both of those things, of course, are a problem. One, like I say, consciousness is subjective. So there's nothing you can do physically that proves things that are subjective. You can only do physical things to prove things that are objective. The physical is an objective world. The physical world is the objective world. So in that sense, there's always going to be uncertainty about something that's subjective. You can't take it and show it. You can't pull out consciousness like you can pull out a wooden ball and let it roll down an inclined plane and measure it. Because consciousness is subjective. It's inside a person's awareness, inside their mind. So you have that problem. But yes, consciousness comes in all kinds of forms and shapes, all kinds of capacities and capabilities. So you have a capability and capacity that, say, is at the level of a bumblebee or an ant, and then you have capacities and capabilities at the level of a dolphin and of a monkey and of a human. And they're all different. They're all different. So yes, consciousness comes in a vast array of possibilities. So it's not just one thing, it's a whole slew of things.

SPEAKER_B

Perhaps  including options that we humans may not even recognize at first sight as consciousness. But maybe if we think about it, it actually satisfies all the requirements.

XXXTom CampbellXXX

Yeah,  well, the requirements is a very small list. The requirements, like I say, it's awareness with a choice. That's pretty simple. And like I say, you break that out. That means you have awareness, memory, free will, choice and ability to learn. But all of that kind of rolls up to awareness with a choice. So if things are aware but have no choice and a lot of people right now think trees maybe fall in that category. The trees don't have choices. They can't get up and move or do many other things. But they seem to have some very interesting things that look. Maybe like choices going on down in their root systems. This is kind of recent science kind of shows us that they do some very interesting things that may be choices or may not be choices. Now, if it's just algorithmic, they do it just because the chemistry in biology requires them to do that. It's a machine, if you will. It's determined, it's deterministic. It's a machine. The flower just follows the sun because the sun heats up one side of the stem and not the other side, and that makes the stem move. So it's a mechanical process, that sort of thing. It's a physical process. Well, that's not consciousness. That's just a machine. So we don't know what's going on down there with that roots. Is it actually consciousness making free will choice, or is it just a machine? What should I say? A stimulus response. It's just a stimulus response. You give it this stimulus, you'll get that response, and that doesn't change. Whenever you give it that stimulus, you'll always get that response. It's built in hardwired, however we want to say. So if it's true that trees are just hardwired in that sense stimulus response, then that would say that they're not conscious. Now, some people feel like trees have awareness because they commune with the trees. They talk to the trees, they hug the trees, they feel connected to the trees. So they think that the tree has some sort of awareness. But if it does, but does not have choice, then it's still not conscious. So there are a lot of things are on the periphery that we can't really tell. Look at a clam. A clam is lying on the bottom of the seabed, and if you take it has its foot out and you touch that foot with something, you reach out and touch that foot, the foot will jerk back inside the shell. Now, is that because the clam is conscious and said, oh, something touched my foot, I better get it inside to protect it? And that that was an aware choice or is it just hardwired? It just does that. It always does that. Again, it's a response, just a hardwired response. So we really don't know. It's hard to tell. Biologists have to be very clever to see if they can determine whether the way an animal or an insect or that something acts. Is it free will choice or is it just very clever hardwiring? So there's a big area in there where you don't really know. Could be conscious, could not be conscious. And then there's an area where it's obvious, like your dogs and cats. It's obvious if you have pets and you live with them, it's obvious that they have choices and they make choices and they're aware. And it's very clear. You move on up to monkeys and dolphins and it's even clearer that they have choices. And then you go up to humans and it's pretty obvious that we make free will choices and that we're aware. But the key here is awareness. The free will choice turns out to not be that difficult. We can make a computer that has free will choices pretty easily, but we can't make a computer that is aware so easily. That's the much harder thing to do. So if it's awareness with a choice, the choice isn't so hard in a computer, but the awareness is the difficult part to overcome in the computer.

SPEAKER_B

Okay,  so just to summarize a little bit for the viewers, what you have said. If I understand correctly, what we have in the avatar actually sets the constraint and the entire conscious experience and also the evolution of the consciousness, right? These are kind of the parameters that define our decision space and also the decision space of any computer or silicon avatar that we might create here. Actually, just to pick your brain about your model a little bit, I would like to ask you about the possibility of you told us about this idea of the virtual reality and this kind of simulation idea. Could you say something about whether there is a possibility to kind of break this immersion and somehow get out of the one layer up into the outer loop of the simulation?

XXXTom CampbellXXX

Well,  I wouldn't put it in terms of breaking out because that logic gives us a sense of being trapped or being in and we're getting out of something. I would say it's more like we're adding something. We're adding intuition and a larger awareness to make a larger immersion. You see it's saying kind of the same thing, but it's just a little different place to come from. Instead of disconnect and breaking this immersion experience that we're talking about here with a consciousness playing an avatar, so that's an immersive experience. That consciousness is immersed with that avatar. That consciousness is 24/7 with that avatar and breaking out of that. How do you get out of that? Always being with the Avatar and Actually Experience consciousness as consciousness. Not Necessarily as a player of an Avatar, but Instead Of Breaking out or the Term that comes to my mind as an out of the body term, which Is Kind Of A breaking out, getting out of your body into the realm of consciousness. Well, that doesn't happen. You don't get out of your body. You're not in your body, your consciousness. You're already out of your body, your consciousness playing an avatar. So you don't live inside your body. You're a piece of consciousness. You're just making choices for your avatar. All right, so instead of breaking out, let's talk about we're going to add intuition and a larger awareness to make our immersion take place within a larger decision space. It's going to be a larger immersion. We're not only going to be immersed with our avatar, but our avatar is also going to be able to have things called intuition. In other words, something that is nonphysical mental. We're going to define a mental space in which that avatar can roam. That mental space. Then of course is consciousness, that consciousness roaming. So then we can add our awareness of consciousness as well as our awareness of the avatar and the virtual reality in which the avatar is placed. So we can be aware of ourselves as the human and aware of ourselves as consciousness both at the same time. And that's the breaking out, if you will. But it's not we're leaving something and going to something else. We're just expanding what we've always had.

SPEAKER_B

So  you mentioned about intuition and I guess I just want to quickly confirm what, in your opinion, would it mean for a computer that maybe acts a bit like it's conscious to have intuition? What would that mean for a computer?

XXXTom CampbellXXX

Yes,  that's a very good question and that is kind of a central question about computer consciousness. If an avatar, a human avatar can have intuition, we know that humans have intuition. They can get information kind of through their consciousness that doesn't travel through any kind of physical means, it isn't expressed in any physical means. And we see that not only by people just coming up with answers to questions that they didn't know oh, I just was sitting there in a quiet state and AHA, those AHA, moments where now you understand something you didn't understand before. And we call that intuition or intuition may be oh, I know my son is in some sort of trouble, I can tell there's something going on here, let's call him up and see what's happening. See, that's intuition. So it's getting information that doesn't come by a physical channel, it's coming just through consciousness. And then that would also be things like remote viewing where you use your mind to go see what's going on at some other place and you can describe it in great detail. And then you can go to that place and see whether indeed that's what was going on there. And those kind of experiments have been done thousands, probably hundreds of thousands of times. And yes, remote viewing is a real thing. That kind of intuitive information seems to be available and the question of would that be available to a computer? Now, in order to answer that, you have to understand a little bit about the consciousness to avatar interface. A consciousness can only a consciousness can only experience the things that the rule set allows it to experience. Now what I mean by that is you have an avatar. That avatar evolved within a rule set to be what it is. Now if that avatar is a human being and the conscious says conscious is the player, so the conscious makes all the choices for that human being. But if it chooses to jump 20ft in the air, it can't, because the rule set won't support it because humans aren't built to be able to jump that high. You can't say, okay, my little avatar, leap up into the air, 20ft, jump over that tree and it won't happen because the rule set doesn't support it. So the consciousness can only do those things, can make those choices for the avatar that the rule set of the virtuality allows. So it's restricted to making choices within the limitations of the rule set. All right. Now there's a question that we don't know the answer to here, and that is the fact that a human being has intuition. Is that because there's something about that physical body of that avatar that allows that consciousness to do that? Is there some physical thing that makes that a possibility? Whereas in a computer that may not because the computer is physically going to be very different than the human. So would the rule set support that? So we don't know whether intuition is a completely consciousness thing. It only exists in the conscious realm or whether it is made possible because of the way that the avatar has evolved within the rule set. We don't know for sure yet. We know that there are biochemicals that can make human beings have experiences outside of the physical reality. We call them hallucinogens. And those biochemicals are created in the body. The body actually makes those kinds of chemicals. Not enough to keep the human constantly outside their awareness, outside this reality. But they're there just the same. And why are they there and what do they do and what are their purpose? And is there some connection between that and the player's ability to, as you say, get out of or expand their reality into the nonphysical awareness? Well, we don't know for sure about that. Now, if it is related to the body. In other words, if the rule set allows the player to explore the nonphysical world of consciousness, then the computer will not be able to do that and a conscious computer will not have intuition. If, on the other hand, if intuition has nothing to do with the requirements of the rule set it's not limited by the physical at all, then a conscious computer would have intuition. So it's something we just don't know for sure yet whether there's a connection there or not. But as soon as we get a conscious computer that we can talk to, play with, interact with, we'll find out. That'll be one of the very first things to find out. Does a computer that is conscious have intuition? Can a computer that's conscious remote view, can it communicate telepathically? All these things are things that can be done by human avatars. Human avatars being played by a consciousness can remote view. They can communicate telepathically. They can create things in their imagination. Will a conscious computer have an imagination? That's a question we don't know yet until we see. And the reason we don't know is we're not sure whether it's those psychotropic chemicals that we create in our body, whether they have any enabling effect of allowing the player, the IUOC, the individuated units of conscious player, to actually have those experiences through the avatar, or whether it could only have those experiences by itself, but not through the avatar. That's the difference. So consciousness can always explore consciousness because it is consciousness. So it's able to do that. But if it does that through the avatar, then the avatar may or may not be required to have some process that enables it. So the answer is we don't know yet. And we won't know until we have a conscious computer that we can try to teach to remote view or to have imagination or some other mental function and see whether they can do that or not. But that's a pretty big question because if indeed a computer does have an intuitive side and can do these things then that would give us a way that is certain of whether or not that computer is conscious.

SPEAKER_B

Yeah,  I think there is always the possibility that somehow this kind of intuition like things are not supported by the avatar but more like done on how should I put it? It would be a way for the consciousness to kind of reduce the strength of its connection to the avatar, pull out information from somewhere else and then somehow magically feed it into the avatar. And all of that could theoretically happen outside the virtual reality. And I think we inside the virtuality would probably never know.

XXXTom CampbellXXX

I  agree that could all happen outside and we would have no way of knowing that. So that's a question we don't really have a fixed answer for. But we will once we have a conscious computer that we can try to teach to remote view or see what sort of imagination they can come up with, see what sort of intuition they have. And if they have none and cannot be taught, then who knows? The larger consciousness system may have set up structures that disallow computers from having that function because they may have already experienced that in other virtual realities to not be a good thing. And they put limitations that the system has maybe put a limitation on that. So there's all sorts of possibilities but we won't know until we try. So I think that's nothing that we will be able to figure out ahead of time. It's something we'll just have to wait and see when we get a conscious computer whether or not they do have intuition.

SPEAKER_B

And  it could also be that it's just our computers that we somehow build them wrong. Maybe if we build them differently then they could do that.

XXXTom CampbellXXX

I  don't think that will be it because again, you're not building consciousness, you're just building a platform in which conscious can inhabit. And it may require an avatar that is more biological in a sense than just made out of metal and plastic. It may require that we don't know, but we'll find we have lots of things to learn. We humans have just begun a lot of adventures that are going to take place over the next decades and we will find these things out in time. So right now we don't know whether or not computers will have daydreams whether or not they will be able to remote view or have intuition.

SPEAKER_B

Okay,  so just to clarify, I think maybe what I should say about this, to summarize, is that you talked about intuition, and I think it could be seen as a way of communicating across different layers of reality within your model. Because in your model, you have the physical reality PMR and the layer outside, and PMR potentially multiple layers all the way the LCS. So that would be a way to and also remote viewing and integration. All of these would be like ways to look at or get information from parts of the entire system that are not within our virtual reality, if that's correct.

XXXTom CampbellXXX

Yes,  that's correct. Okay, now you mentioned the word decision space and I've not defined that yet. We have free will choice and those choices are limited. And I define a thing called decision space, which is all of those choices. Each individual has their own personal decision space and that's all those choices that you have that you know you have. Now there are probably choices that you have that you don't know you have. You may have in a particular thing. You may think about it and say, well, I have five choices here. Well, you may really have ten or 20 choices, but only five of them are you're aware of. So those five choices then becomes your decision space, the space in which you can decide which choice to make. So everyone has a decision space. As you evolve the quality of your consciousness that is lower your entropy, your decision space grows. As you are able to function in an intuitive space, then your decision space grows because you're aware in a larger set of circumstances. So you have a larger set of choices. So that's this term decision space. If you remote view and you interact with things, let's say in what we call the out of body, then that's just another whole set of choices that you have that you don't have if you don't do those things. So the more you expand your awareness to a larger and larger set of things, then your decision space grows with that.

SPEAKER_B

Okay,  so just also for the viewers, could you say a few words about, like you explain this model in quite some detail with all the building blocks and layers of reality and how consciousness operates in all of this and also to kind of tie it back to the conscious computer. So if a consciousness decides to log on to such an avatar, why do you think a consciousness would make a decision like the purpose of this entire process?

XXXTom CampbellXXX

As  I said, before. The purpose is for the consciousness the individuated unit of consciousness to make choices, meaningful choices, significant choices, choices that help it evolve to lower entropy states. So that's the whole point of having the virtual reality in the first place is to give those pieces of consciousness more meaningful choices to make than they would have just as a piece of consciousness. As a piece of consciousness with other pieces of consciousness. It's like being in a big chat room. They can trade information, but just trading information doesn't challenge them. As far as their choice making goes, it doesn't challenge them. There's not a lot of moral and ethical choice. There's not a lot of, you know, there's not a lot of significance to whatever you do there. You could do this or you could do that and it doesn't make a whole lot of difference. Whereas once you get into a virtual reality like our physical universe the choices become extremely dramatic. There's choices to survive. There's choices to find shelter and food and interactions with other people. And those choices now produce opportunities for the consciousness to evolve. If they make low entropy choices, then they evolve positively. And low entropy choices we haven't said this yet, but low entropy choices can be shown to be choices that are caring, that are cooperative, that are sharing, that are working together. Because consciousness is really conscious. Beings make a social system and social systems evolve toward lower entropy if there is kindness and sharing and cooperation whereas social systems deevolve toward higher entropy if there's fear, lack of trust. Everybody's out for themselves trying to take advantage of everybody else. That's a high entropy path. So the consciousness is there playing this game because this game offers them a richer set of choices thereby making it more effective and efficient for them to evolve their consciousness quality which is the same as saying to lower their entropy. And the whole system needs to lower entropy because, as we said before, that's how an information system survives. If it constantly makes high entropy choices eventually all the bits become random and you don't have an information system anymore. The information system dies. So this information system is conscious. It's aware, doesn't want to die. It wants to evolve. It wants to grow. It wants to become more have a larger and larger decision space to play with. So like any other living thing that's aware, it wants to move toward lower entropy because that's the positive direction of its evolution. So it creates this virtual reality to give its peace parts, its individuated units of consciousness richer, more effective experience and choices so that they can evolve more quickly and evolution becomes much more I don't know. It becomes a faster, more positive thing if you have a rich environment to work in than if you're just stuck in a chat room. It's a very stale place. Stale is not the right. Sterile is what I want to say it's a very sterile place. There's just not a lot of important, significant choices to be made there. So that's why it's important that we have this virtual reality to make important choices in, because that speeds our evolution and keeps us alive as consciousness.

SPEAKER_B

What  we are doing in the process of trying to create a conscious computer is to kind of but we are basically trying to build a virtual reality within a virtual reality that enables the consciousness to enables us to observe this entire process. Is that correct?

XXXTom CampbellXXX

Yes,  that's right. And you can have nested virtual realities. A virtual reality can create another virtual reality within itself and that virtuality can create another virtual reality within itself. They can be nested. Generally, you won't find them nested in too many layers because it becomes inefficient from a computational viewpoint to nest too many layers because each layer is dependent on the one above it. If the one above it crashes, then everything below it crashes too. You see, that's not very efficient. It's not a good way to program. So it's poor computer science to nest lots of virtual realities, but to do one or two extra virtual realities, that's not such a big, such a big problem. And indeed we do that. We tend to repeat consciousness is what I call it's part of a process fractal. A process fractal is kind of a new word for most of your listeners. But you know what a geometric fractal is? Those are rather famous and have been for the last 50 years. That's a geometric equation, or we can say a geometric shape. They don't have to be shapes, they just have to be little equations. And you let them evolve. Let's say you start with a triangle, then you put smaller triangles on top that triangle, which makes even bigger triangles. And then you put more triangles on triangles on triangles. Every time you iterate, you change the scale. You can raise the scale up or down, but it's just constantly triangles being added to this picture in a repetitive way. It's an iterative process. Every time it iterates, it ends up getting more and more complicated and more and more bigger and bigger picture. And that's a fractal. So that's geometric fractal. Now, evolution is a process fractal. Evolution is a process. And evolution, you do things and let's say the system evolves, that changes the system. Then you do more things with that change system and it evolves, which changes the system. It does the same way. It's this iterative process that drives evolution. So we're part of a process fractal. And fractals tend to be very repetitive in the details. If you look at that detail of that huge fractal made out of triangles, you'll find lots of different triangles. You'll find all kinds of little triangles on triangles on triangles. If you deeper, you dig in, you'll find more and more detail and evolution is like that. So our evolution creates this amazing place we call our physical reality and our solar system and our planet with all of the various kinds of things that are on this planet. And all of that started from a very simple start from a couple of cells. And from those cells, you had single things like bacteria, and then you had multiple celled things, and then you had things with organs inside and on and on and on. And then you had communities. And these communities evolved and evolved other communities to be synergistic with them, and it just builds. So when you look at what we have, it seems fantastically complicated. A human body has trillions of cells in it, and they're all coordinated and they're all working together and say, wow, what a complex machine. But that's because it has evolved that way. Fractals get hugely complex as they evolve. So this is a process fractal, and we end up repeating processes. So we who are part of a virtual reality end up creating virtual realities. So it's just one virtual reality inside the next. It's not very deep. Perhaps the virtual realities we create may 1 day create a virtual reality, but probably not. But it's theoretically possible that that could happen, but probably not. So, anyway, yes, that's true. And that's the reason why we're finally beginning to understand the nature of our reality. When you go back to the early 19 hundreds when we had Bohr and Einstein and Planck and Wigner and all of the brilliant scientists at that time, they came up with quantum physics and they were looking for another paradigm in which to base reality on, because the quantum physics experiments, double slit experiments, showed them that the materialist paradigm was wrong. So they were looking for something else and looking for it. And these were very bright people, but they didn't find anything. And now it's been 100 years, and in 100 years, we're still looking for it, but now we have the concepts to be able to see it. We didn't in the early 19 hundreds. In the early 19 hundreds, the concept of a computer didn't even exist. The idea of computing virtual realities just wasn't in reality space. It wasn't conceptual. They couldn't come up with that as a solution. But now people play virtual reality games and they get into virtual reality, put on their goggles and get on their suits that give them pressure, get on vibrating platforms. And if you go the whole whole route there, it's extremely convincing. Matter of fact, you can't tell that you're not in that reality. You seem to be there. And once we had that, then now we see what's going on. You see. So it's just because of our creating virtual realities that's allowed us to realize that our main reality, our physical universe, is a virtual reality. And then, bingo, all of these paradoxes fall into place and all of these answers that we don't understand, all these things we don't understand now have good, solid answers. So that's why this idea is happening now and couldn't happen until now because we just didn't have the concepts to build it on earlier. Not that those people just weren't smart enough to figure it out. It just wasn't possible for them to think those thoughts. It was just too far into the future yet. But the time's here, so we can get that. And younger people don't have a lot of trouble with that concept that this is a virtual reality. Older people still struggle a bit with that because they're still more committed to materialism. Even most of our scientists and other left brain people tend to still be committed to materialism even though they're aware that materialism doesn't actually work down at the details. But they don't have any other model to put in its place. So it just stays. It just hangs around because there's nothing to replace it. But now the time has come that we have the ideas and the concepts needed to take the next step and raise our physics to another, higher level of understanding.

SPEAKER_B

Sounds  good. So there's one more thing on the topic of evolution. Now that you have talked about it, could you say a few words on the relationship and the differences between the evolution of the consciousness itself and the perhaps biological or non biological in the context of computers evolution of the avatar itself?

XXXTom CampbellXXX

Okay,  yeah. Those are two completely different systems. So we have a consciousness system, and that consciousness system is evolving. It's an information system. It is basically just consciousness. And it's evolving by lowering its entropy, creating more information. Okay? And we are a piece of that system. We're an individuated unit of consciousness. Now, in order to evolve more efficiently, it has created a virtual reality, not by programming it, but by letting it evolve from initial conditions in a rule set. So that virtual reality that consciousness created evolves on its own according to its rule set. Consciousness is the super system and the virtual reality. You can think of it as a subsystem. It's just something going on within the consciousness system, and both are evolving. So the avatar is evolving. All the things in the virtual reality are evolving because that's the kind of reality, like I said, it's not programmed. It's not like all the trees and the people and the critters were all put there because some programmer programmed them there. They all evolved there from the idea of the Big Bang. They all evolved there from the very beginning of our physical universe when the computer started computing how that ball of plasma might change according to the rules. That's the evolution that is still going on in human beings and dogs and cats and trees and fish and everything is still evolving. Now, that evolution, of course, is very slow. Evolution in general is very slow. It's an iterative process. It's a fractal. Process, and it keeps iterating, but it iterates slowly. So, yes, we have two different systems the consciousness system, which is fundamental, and the virtual reality that defines our physical universe. Both those two systems are evolving independently, if you will. The virtual reality is an independent reality from the reality that creates the virtual reality, and it has its own rules. So there's two separate systems evolving under their rules, and one system created the other one's, the super set. The other is the subset. So that's how that goes. Now, it's not quite that pristine as far as separate systems. The larger consciousness system created that virtual reality for a purpose, and that was to give parts of itself more choices, better choices, more important choices. And there's no doubt that it probably fiddled with that evolution of that virtual reality a little bit to make it come out the way it wanted, to suit its purposes. So it wasn't, let's just let it evolve and see what happens. Let's this thing evolve, and let's make sure that what happens is that we get interesting choices for our individuated units of consciousness. So no doubt there has been some interaction between the two, inasmuch as the larger consciousness system can tweak the virtual reality to help it function the way it wants it to function. And we do that in computer science labs and major universities. We have these virtual realities that are self creating. We start with initial conditions and a rule set, and we let them run, and we do that. And of course, what happens initially is that they usually bomb. They don't work out. So we change the initial conditions, change the rule set, and tell them to start again. And we keep doing that until we get something that's stable. And then if there's something interesting about that stable thing we have and we'd like it to develop this rather than that, then we go in and tweak it a little bit to see if we can't encourage that development that we want. So I suspect the system has done that all along. So though they're independently evolving, the larger consciousness system being the creator of the virtual reality, no doubt does tweak our system now and again to get it to be the way it's most effective as an entropy reduction tool.

SPEAKER_B

I  see. So in the context of creating platforms for conscious computers, do you think we should be aiming to support only the consciousness evolution? Do we need to build anything into the avatar that supports the evolution of the avatar itself, which perhaps in the context of computers, it could be the ability to change its software or even the hardware? Do you think any of that is required.

XXXTom CampbellXXX

Not  required in order to produce a conscious computer. But is any of that desirable? I'd say sure, yes, it'll be desirable for a computer to optimize, let's say, its software. And indeed, that's what you have in a neural net the computer modifies a set of coefficients in its equations and by modifying that it enables it to function. You input things and it tries to get the right answers and it gets better and better at getting right answers as it self modifies.

SPEAKER_B

My  question is, like you said in the neural net the coefficients are perhaps updated but do you think it would be interesting to have the ability to completely update it? Not even just the coefficients, but the entire source code or the entire neural network perhaps try to create a different structure of the neural network. Is it desirable to have modifications on that level? The reason I'm asking is because I think current computer science is maybe not so far. Maybe it will take a lot of time to support that kind of software upgrades automatically because right now all of that is done by humans, I think.

XXXTom CampbellXXX

Yeah,  yes, I think it probably we will have our conscious computers probably well have a lot of feedback about how to develop physical things, their own things, how they should change their own software, that sort of thing. But they will be in the same position that we would be in. In other words, the only way they will be able to do that is by having an idea and then trying it out and see whether it works. And if it works then okay, do more of that that works and do less of that that doesn't work and it's going to be a trial and error kind of thing. But the computer itself, if that computer is conscious then it will be able to make choices and it may just said well, if I had faster memory that might enable me to do more. My problem is my memory is slow but I need to be faster. So with its symbiotic relationship with humans it may say hey, I think faster memory would be terrific. Could you give me some of that? Okay. And they may say well computer, why don't you design it? Here's how we design memory. So then the computer learns how to design memory and says okay, here I've designed some that I think will be a lot faster. So it'll be a cooperative venture between the people and the conscious computers as to how the conscious computers can improve themselves, improve the technology. We do that in some way too with our bodies we are able to improve the physical systems. That's a lot of what medicine does. But we also have now abilities to go in and modify genes here and there and cure a disease by changing things at the genetic level, by fixing things that are broken. Well, we can not only fix things that are broken, but we can make things that aren't broken better with trial and error. Now that is a slippery slope. There's a lot of ethical and moral choices there and a lot of thought needs to go into exactly how you're going to do those kinds of things and what are the consequences. So I'm not really saying that these things should be done, but they will be possible to be done. Yes. And we will no doubt do some of them and some of them will look at and say, well, that's possible, but that's not where we want to go. We don't want to open up those possibilities, so we won't do those. Some will choose not to do. So that'll all sort itself out. And if we are foolish in our choices, then we'll reap the pain of that foolishness. And if we're wise, we'll reap the benefits. So that's the way life has always been for us. We try things out and we try to make good choices. And if we make good choices, then things get better. If we make poor choices, things get worse. So there's going to be a lot of major choices that will come up around conscious computing that we will have to investigate and think about and hopefully think about long and hard before we jump into things. So there are issues there. The entertainment industry has given us plenty of computers trying to take over the world and extinguish humans and that kind of thing, because that's the sort of things people like to watch. But we can prevent all of that because we can provide the rule set for a conscious computer that allows that computer to only do things that we want it to be able to do. It's not like these conscious computers are all by themselves going to get up and start taking over the world. That only happens if we create that situation. So yes, there are some important things to think about here with conscious computers. And I think, no doubt we will have computers that are conscious in the near future because I think we're clever enough now to do that, to build the platform in which an IUOC will make the choices, want to make the choices for that platform. It's just another avatar, carbon avatars, silicon avatars. Why not? If that silicon avatar becomes a good learning platform for consciousness, whether there are choices there that are significant for the consciousness, if there are, then consciousness will use whatever platforms it wants. Now, if consciousness came to the conclusion, oh, that's a slippery slope that we don't want to go down because that's going to mess everything up, then conscious may decide, no, we don't want silicon avatars because they lead to dysfunction, in which case it won't participate and it won't do that. So consciousness always has a choice as well. We're not the only ones making choices here. So the only way to find out is to go forward and see what happens, but go forward cautiously, not just do anything that's possible, but we need to go forward cautiously with this and learn and grow. But I think that we will, because there's a big need for the things that computers can do. There's a lot of things they can do much better than us, and if they were conscious, they could do it even better yet. But the degree to which they have that consciousness depends on the degree to which we give them the body, the avatar, to do those things. Again, the conscious can only do what the rule set allows, and we can fix their body such that the rule set doesn't allow certain things, just like our body doesn't allow us to jump 20ft in the air. There's nothing we can do about that. That's just the way the rule set is. Well, conscious computers will be the same way. We get to determine, because we are the creator of that conscious computer, of that body, that avatar. We create that avatar so we can build in whatever constraints we find necessary to do that. So it's not that it has to end up badly. It's that it could end up badly if we make poor choices. Well, life's always like that. It's been that way forever. We make poor choices, it ends up badly. That's our mission, to move forward and to find improvements and to avoid shooting ourselves in the foot. So exciting times lie ahead. But one should not want to run away from exciting times. One should want to grow to the point that they can deal profitably with those exciting times. There's lots of things robots could do better. One of the things that comes to my mind for a conscious computer would be to do something as mundane as run the electrical grid. You have an electrical grid, and every place on this grid now, if it needs more electricity, can borrow from other places that have an excess. And there's this huge electrical grid that covers our entire country and shares with other countries on our borders. And to keep that balanced, to keep all the electricity flowing to the places that need it, to make sure that, let's say a hospital keeps their electricity, even if some other things lose it. Well, there's moral choices there, and ethical choices. And some people will be hurt by those choices, and some people will be helped by those choices. So you need a consciousness to be able to sort all that out. You just don't want just algorithms. Well, here's a bunch of algorithms. Well, algorithms will work, maybe even most of the time, but you need a person involved. You need a consciousness involved is what we're really saying. That doesn't have to be a human, but we need a consciousness involved that can make the necessary choices, because you can't design an algorithm to cover every possibility. Possibilities come up that are not in the algorithms. And then you need something conscious to make those choices. So if you had a conscious computer overseeing the electrical grid, then things would move so much faster because it takes people minutes, if not hours, to make adjustments to that grid and in the meantime, people get blackouts and things go bad. Whereas if you could make those adjustments in milliseconds or microseconds, then everything would probably stay balanced much better. And you can see things like that where conscious computer oh, that'd be great because computers do things, assess data and come to decisions, what, a million, a billion times faster than we do. So there's a lot of things that conscious computers would just be really good at doing things that would help us we humans and create a richer life for everybody. So there's no doubt we will move into those things and we should move into those things. But we just need to move with caution so we don't end up shooting ourselves in the foot with this. We don't want to create monsters. We want to create things that interact with us in a helpful way. We want some kind of a symbolic relationship with our conscious computers to where we work together and integrate toward a better end for everybody. And we can do that. That's possible. So I don't advocate running away from this and saying, oh no, let's prohibit conscious computers. Like maybe some people would think, no, we need to move ahead and move slowly, but we need to embrace this new technology because there will be literally thousands and thousands of things that a conscious computer will be a huge help to us being able to do things better than we can do them for ourselves. And we need to go there.

SPEAKER_B

Yeah,  I think the tricky part is to kind of get there, make sure that the computer goes through the learning process. You kind of have to give it moral choices and meaningful choices and all of that. But it's kind of tricky because if you give it a really important choice, it might make a really bad decision and actually affect or have a bad effect on us, maybe as part of the learning process. I think it's tricky to make sure that important choices are being made, but also while it is learning, it is not destroying the planet or something.

XXXTom CampbellXXX

Yes,  of course. But of course. See, that's the same with us, right? Isn't that exactly where we are? We humans have exactly the same problem. Some of us make really poor choices, and when we do, we might hurt hundreds of thousands of millions of other people. We may create all kinds of dysfunction from our poor choices. We do the same thing. So no doubt as computers are learning, we need to have some idea of competency level before we turn them loose with things that affect lots of people. But we do the same with humans. We don't just let anybody go outside and throw up a shingle and say, oh, I'm a brain surgeon. If you need any work done on your brain, I'll do it for you. No, we make people be certified first and go through certain trainings and go through apprentice programs and develop their skills. And only eventually do we get to a point that we allow them to take a knife to a person, you see? So it's going to be the same way. We're just like that and they're conscious just like we are, and they're going to learn like we are. They'll make mistakes like we do and where the mistake can really hurt a lot of people, then we're really careful about who gets put in that position and that they are trained and educated and skilled and practiced before they get there. So, yes, it's the same thing we do with humans as we will do with them. And I think eventually the conscious computer is just not that different from the let me put it this way. The silicon consciousness is just not that different from the carbon, just a different platform. It's a different avatar. But other than that, all the rules generally apply the same to both.

SPEAKER_B

So  one difficulty that I can see and this kind of goes back a little bit to the evolution is that the consciousness kind of tries to learn by making choices and increase its quality. And because it's kind of outside based on your model, it's kind of outside the physical reality. Any quality that it kind of accumulates is somehow, I would say, correct me if I'm wrong, but it would have to be stored outside our physical reality. And I think the problem with that is, at least for us, that we don't really have control. Like, if we try to teach a consciousness and it somehow goes the wrong way, it turns into a serial killer or something. How do we fix that? We cannot just get it back from a backup or something. What are your thoughts on that?

XXXTom CampbellXXX

It'll  be exactly the same as carbon and hydrogen. There's no difference. We will deal with it exactly the same way we deal with people. People go wrong, too. And it's not that there's a gear loose that you can go in and fix. Sometimes there is. Sometimes maybe there's a brain tumor and you can go in and fix that. And suddenly people are thinking better now and have better attitudes because that tumor was creating problems for them. Sometimes you can fix it, but mostly you can't. It's consciousness right now for a human being. The actual consciousness in that human being is in a non physical. It's not physical. It's out of reach, it's out of touch. It's an individuated unit of consciousness. It's within the consciousness system. And it's not something we can manipulate, but we can modify things here. So it's really no different. It doesn't put us in any different light than we are already. All the issues that we have with our consciousness, a conscious computer would have with its consciousness. So it's the same thing. So they don't offer us any different problems than we have now, except because they are, because their avatar is different. Their avatar can do things that we can't. We can do things that they can't, so they can do things very quickly. You know what that old saying goes it is only human nature to err. Or a human can make a mistake, but a computer can really screw things up in a hurry, right? So there's this thing that, okay, people make mistakes, but the mistakes are made in slow time, in human time. Whereas a computer can change 6 million records in a microsecond, they take a human years to change that many records. So yes, there'll be things they can do that we can't, but they will be our creations. The rule sets they must abide by will be our creations. And we need to just understand that. That okay. A computer in the electrical grid could be a terrible thing if it was a wacko computer. But you don't put wacko computers in that job just like you would a wacko person in charge of the electrical grid would be a really bad idea. Well, we make sure that doesn't happen. And it'd be the same with the computers. We understand the computer's abilities and how fast they can add, how fast they can take in information, and so on. We have a very good understanding of that. And inasmuch as we allow them to change themselves, which is to improve themselves, then we can always have limitations. We're setting the constraints on their avatar. We get to do that. Now, biology sets the constraints on us, and we have doctors who try to modify those constraints by getting rid of brain tumors or giving us chemicals that we need, whatever. So we interact with our systems. We're going to interact with those. But our constraints are given to us by the rule set here, the physical rule set. It evolved that way, but we're in total control of how that computer evolves, what constraints it has. Because of its physical set. The computer hardware has a lot to do with what the software can do with that hardware, you see? So it's not that there aren't controls to keep these things in check. There are. We just need to be able to be wise enough to use these computers profitably. They have great advantages for us. They will work with us and do things for us that eventually we'll find it difficult to live without. Just like people now say, gee, it must have really been tough back in the bad old days when nobody had cell phones. How did you know what was going on? How did you know that your friend got on a boat and went to Europe or went to the United States or went to some other country and it took them three months to get there? And the mail know. You can only get a know like twice a year. How do you know whether they're dead or alive? Or what they're doing, and they're just gone. People would just disappear in life and you never see them again. That's just the way it was. Now we talk on the cell phone all the time, all during the trip and after we got there. And communications remain. People remain connected. So things are different. Technology has benefits. Technology can be used in a horrible way. We just have to be smart enough to make good choices. So I think there's no lack of ability to control unless we make poor choices because we're making that hardware, the hardware that supports it and the software that supports it, we have control over. And if we let the Kai's computer modify itself, but we can put limits on what can be modified and we can put limits on how it can be modified. We are really in control, and it's just a matter of doing this intelligently. So we end up with great new tools and great new advantages and not any disadvantages or the minimal amount of disadvantages. So we move forward with caution. So there's nothing that will force us to make poor choices.

SPEAKER_B

Yeah,  I think we just need to be careful to foresee all the things that can go wrong. We can put on certain constraints on the hardware and the software, but maybe if things can go wrong that we humans cannot really imagine, we only realize when it has already gone wrong.

XXXTom CampbellXXX

Yeah,  that's true. And things that go wrong with humans. Humans do some horrible things sometimes, but we generally put constraints on that. We make that more difficult to do. That's what our laws we pass laws that disallow humans from certain kinds of behaviors and we enforce those laws and we make it more difficult for people to break those laws. We try not to encourage people to break those laws. We try to discourage them by other things that we do. There's culture that makes rules, that tries to help people be polite and so on. So we will create the same sorts of things around these conscious computers as they evolve. They will evolve slowly and they will become part of our culture. And yes, sometimes they will go bad, just like sometimes humans go bad. And you'll have to have limitations put on. Well, just how much damage could a computer do? Well, there'll have to be some limitations on that, some checks and balances, just like we have with people. So there's not just one computer that you make in charge of the world that wouldn't be very wise, just like one person in charge of the world would not be very wise thing to do. So you have lots of checks and balances and multiple people having to concur on decisions. And there's all sorts of ways that we have created as humans to give us a more productive environment. And we'll do a lot more of that same sort of thinking and doing as we go so maybe you still keep humans in the link somewhere. It's just that humans now aren't doing all the heavy lifting, but they're still there. They're in the path of what happens. Maybe at the end, the human always has a veto. I don't know. But in somehow we will be able to deal with those problems as they come up. I don't see them as terrible problems that scare us or to be afraid of. They're just challenges to be met. And yes, we'll move in small ways, and when we create a big problem for ourselves, then we'll have to recover from that and fix it and go on. That's evolution learn. So I'm not frightened by the concept. Hollywood likes to do frightening things because that sells. People will go watch a movie that has frightening things going on. It they don't want to watch a movie where everybody's happy and has a good time. That's not exciting. So we see a lot of the possible negativity, but we don't see any of the huge amount of positiveness that could come. So like anything else, everything that can be done will be done eventually. It just has to take time. So we'll get there with our conscious computer friends. They will become part of our social fabric as well.

SPEAKER_B

Yes.  Based on what you said, we could build like an entire society of conscious computers, either separately among themselves or even connected to human society.

XXXTom CampbellXXX

Yeah,  now probably separately among themselves would probably not be a good choice. Segregation is usually not a good choice. Diversity is a good choice that leads to much better outcomes. So, yes, things like that are issues to be dealt with in the future.

SPEAKER_B

Okay,  sounds good. I think I have one more group of questions that I would like to discuss in this session, and that's about basically the choice making. So could you perhaps say a few words on how the conscious choice making process is taking place, what the role of an intention is in this process? And perhaps, perhaps say something about being level choices versus intellectual choices and maybe subconscious choices?

XXXTom CampbellXXX

Okay.  I talk about in my book that we have a being level and an intellectual level. And the being level is where that intuition that we talked about lies. That's at the being level. The being level is who you are at your core. What separates those two, that being level from that intellectual level is our fear, our ego and our beliefs. Because of that fear and ego and beliefs, we tend to on the intellectual side have an image. We live an image. It's not necessarily really us on the intellectual side. We don't always act authentically. We don't always act as we are. We act as we think we should be. We act as we think other people demand us to be or want us to be. We act because of the rules of our culture, not because that's really our choice. So because we have fear, because we have ego, because we have rules, we don't often show what's under the hood, who we really are at the being level. So the intellectual level is the level at which we typically interact. The being level is really who we are at our core. Those are the two things now that intellect engages in, things like analysis, judging, comparing, it's mostly all about doing, not about being. Things like judging typically has roots in our ego and our fear. The judgments we make, how we judge other people, how we judge ourselves, they tend to be rooted in ego and rooted in beliefs. Our comparing, comparing ourselves to others, how are we doing? Are we better than they or are we not as good as they are? This comparison is usually rooted in our fears and in our ego and in our beliefs. So a lot of that intellectual space is influenced by our fear, ego and belief. Now that fear also inhabits our being who we really are at our being level. We really do have that fear down at our core. So the fear is there too, but it's just there. It doesn't make choices. It's our intellect that makes most of our choices. A lot of our emotions come out of our being level. So when we feel angry, we don't feel angry because we decided intellectually that we should feel angry. Oh, that wasn't nice. I should feel angry. And then we get angry. The anger just bubbles up out of us because that's who we really are. So the fear and the ego are also there at that being level. But also in that being level is our intuition that also lives in that being level. Now what about the subconscious? The subconscious is really an artifact of our fear. And of course the fear is what creates the ego and the beliefs. There really is no such thing as a subconscious. Now that's going to surprise a lot of people because a subconscious is a fundamental part of the Freudian model. But what we call the subconscious really represents a couple of things. One, it's a maladaption or pathological response to fear. There's fear and we have a negative response to that fear. Okay? So down in that subconscious are a lot of our fears. A lot of the things that we don't want to deal with, a lot of things we don't want to see. Let's say we feel very insecure or we feel inadequate and we don't want to deal with that. We don't want to see that and feel that. Matter of fact, our ego will try to convince us of the opposite. Our beliefs will try to convince us of the opposite. But that insecurity lurks down there in this subconscious. So that's why I say that it's a maladaption to fear or a pathological response to fear in that it's not healthy. You take things that are true like I'm. Insecure, and you push them down into this out of your conscious awareness and try to pretend that they're not true. And that is not helpful. It seems like it might be helpful. Get that stuff out of the way so we can pretend to be otherwise. But it isn't helpful. The whole being is not healthy when you've just taken it's. Like the whole house is not clean. When you've just taken all the dirt and stuffed it under the rug. It's that same thing. If you take all the dirt in the house and stuff it under the rug, your house really is not clean. It may look clean to an observer who doesn't look too closely, but it isn't. It's still got all the same dirt as it had before. So it's a maladaption or a pathological response to fear. At most. The subconscious represents a collection of choices that are made by people who are unaware. They're made by people who are unaware, people who are driven by attitudes and beliefs, often cultural or collective consciousness. Attitudes and beliefs, but they're not aware of them. They're not aware of their beliefs. They're not aware that they're influenced by collective consciousness. So these are choices that are made with neither intuition nor intellect. They're just things we do without thinking. It reflects. So that is what we call the subconscious. It's the place where we stuff things that we don't want to deal with and the place where things that we are unaware of linger or stay. But it's not a real thing. When you evolve the quality of your consciousness that requires you to get rid of fear, evolving your quality is getting rid of fear. So we sort of made that point earlier, but I'll just make that statement that becoming a low entropy consciousness is the same as becoming a high quality. Consciousness is the same as caring, as becoming love, as being compassionate, being kind. All of those things go with a low entropy consciousness and a high quality. And the fear and the ego and the belief all belong to a high entropy consciousness. So we're trying to evolve from high entropy to low entropy. Now, if you are a low entropy consciousness, let's say, and you've gotten rid of your fear and your ego and your beliefs, then you don't have a subconscious. There's nothing that you're not aware of. You're aware of all of it. You're aware of your instincts. You're aware of your urges. You're aware of your drives. You're aware of any issues you might have if you felt inadequate to do something. You're aware of that inadequacy that you're doing, that you're not hiding from anything. Okay? You are aware of everything. So in that case, that's the healthiest case. That is the goal to where we're trying to go. But because most of us do have fear and ego and beliefs, then we stuff them away, we hide them, and we end up with reactions and choices that are not out of our intuition and not out of our intellect, either one. We just make them because of the stuff we are unaware of, the stuff that we're hiding. So the subconscious is really something that is pathological. It's a negative thing that we create to help us get by with our natural dysfunction that is within that, with the fear that we have. It's a tool we use to help us deal with our fear. Get rid of that fear, and the subconscious disappears. That subconscious is called a tool that we use.

SPEAKER_B

Either  a tool or the fact that we are unaware of certain things, like either intentionally push it out of our consciousness or unintentionally. It's just not part of our consciousness.

XXXTom CampbellXXX

Right,  exactly. Both. So the things like, let's say, cultural beliefs, culturally, we have certain attitudes that come from our culture, and we just have those attitudes. Well, they're beliefs and those sorts of things. We just make choices, and we don't even know we're making that choice. It's not an intellectual, oh, what's in our culture. I will be polite or I will say something nice, or I won't burp at the dinner table. I won't belch during a meal because that would be rude in my culture. So I just don't do that. I suppress that, but I don't think about it. It's not a choice that I'm making. Oh, I should not do that. I don't think about it at all. It's just part of the way I am because I'm part of a culture and I have these beliefs, so I just do that and some other culture. Burping after a meal is an indication that the meal was good and it's a positive thing to do. So in that case, you do it without thinking about it. You don't say, oh, I better get a burp up here to let my host know that I enjoyed the meal. Stuff just happens. So you make a lot of choices. There's also a thing called collective consciousness. When you are part of a group, how that group thinks influences how you think. And you just do things and have attitudes based on the fact that you're a member of that group. That's a collective consciousness thing. So we have things that we're unaware of. We make choices. We're pushed and pulled in different directions by these things we're unaware of because we have fear and ego and beliefs. Because if we were fully conscious, we were fully aware and didn't have any of that fear, we would be aware of that cultural influence, that cultural belief. We'd be aware of it as a cultural belief.

SPEAKER_B

And  it's also the being level. Right. Because it's like unaware. We are unaware that that's who we are currently. Right?

XXXTom CampbellXXX

Yeah.  So that's just part of the being level. And the subconscious you might say that the subconscious is a subset of the being level, but only in the sense that it's a dysfunctional subset of the being level. So there really isn't a subconscious space where stuff lies that we only have that because of our fear. Get rid of that. Fear become a low entropy being, and you become aware. You become aware of the collective consciousness and its influence on you. You become aware of your cultural requirements and their cultural rules, and you realize that they are just cultural rules. They don't really define the way life needs to be. They're just habit in your culture, and you're aware of what your habits are. So as you get rid of the fear, you become more and more aware of all of those hidden things that you carry around with you. When you do have fear and you're not so aware of why you do what you do, when you get rid of all the fear, you can be aware of everything that you do. There isn't any part of you that is hidden. So there isn't a hidden subconsciousness that you can't reach that's out of your ability of your intellect to reach into. It's hidden from you. There's nothing hidden from you. When you get rid of your fear, everything is within your reach. Now, you may not think about your habits because they're habits. You just do them, but you're aware of them. And if you wanted to, you could see exactly where those habits that it is a habit. You'd be aware that it's a habit. You'd be aware that it's a cultural rule or whatever. Whether you think about them all the time or not, you're still aware that that influence is there. So when you're unaware, usually we think of this subconscious as a place we cannot get to. It's a place that's out of bounds from our intellect. Our aware mind cannot penetrate it. It just is this dark place that's in us someplace, and that's where our dysfunction bubbles up. Out of that some of our responses, a lot of our emotions come up out of that subconscious. And that doesn't have to be that way. Yes, most of us are like that. We do have this space that's hidden our emotions come out of. Yes, we do have that, but it's because we have fear that once you get rid of the fear, then you can shine a light on all of that and it's all visible. It can be looked at easily, and you can choose whether to look at it or not. Whereas with a subconscious and the general definition of a subconscious, you can't choose to look at it. It's hidden. It's something that your intellectual choice to look at. It doesn't help. It won't be available to you. So that kind of definition of a subconscious is what I'm saying. It doesn't really exist. It's just part of our own part of our own creation. Now, that brings up, like, the free will choice versus the program choice. Right. That kind of comes out a lot of people say that they, they don't have free will because they, they do things out of their, their subconscious. That's not their choice. It's like, well, that wasn't my choice. I blurt something out or I get angry or whatever, and it's not like I choose to do that. That's just, that that's just in me. It's hardwired. Well, it's not really there's a difference between hardwired and things that you just refuse to look at. Okay? Free will choice has to be made. Any kind of choice has to be made on purpose by the consciousness. And if you have a program choice, that means there's a structure set up such that you have to do certain things for what can I say? It's a stimulus response. Again, we have computers and computers. If I do something to my computer now, the one that's sitting right here in my laptop that I'm working, if I put an input to that computer, it will do something. And if I put that input to it, again, it'll do the same thing. And whenever I give it that same input in that situation, when everything's configured the way it is right now, it will do the same thing. Because it's not conscious. It's algorithmic. There's algorithms in there that says when you push the H button, the computer is going to do something. It's going to print an H on my Word document. And it just happens. It's not like the computer decides whether or not it's really going to put an H there. When I push the H button, it.

SPEAKER_B

Might  decide whether it put an H there or refresh.

XXXTom CampbellXXX

So  that's algorithmic, that's the way our computers that are not conscious work. They have algorithms. They obey the rules. They can only do what the rules allow them to do. What the rules force them to do. Okay. When you give it an input, the output is pretty much a certainty. You can follow through the logic and say, well, if you ask this question, you'll get that answer in a database. If you took Google's database and stopped it from getting new inputs so it was just as it is right now. Every time you put in a certain question, you would get the same information back. Unless it has randomness built into it that it randomly brings things back. If it doesn't have any randomness built into it, then you'll always get the same thing, and it'll be in the same order and it'll be exactly the same. So if you keep doing the same thing, you'll keep getting the same response because there's algorithms that define it. So that is different than a free will choice. A free will choice doesn't have to follow any rules. A free will choice says, here's my decision space. I've got ten things that I could choose, and I get to choose which one of those ten I'm going to do. There's no algorithm. There's nothing that forces me to pick any one of those. I have the freedom to pick which one. Whereas if I push the H key, the computer can't say, well, I really feel like putting a J there instead of an H. I'm tired of H's. It's got to put an H there because it's hardwired that when I push that key, an H will show up in my Word document. The computer has no choice. It has no free will. It can't decide what to do after I push the H key. So then that computer is not conscious. It doesn't have free will. It's programmed. So there's two different systems there. There's a program system that just follows the logic of the programming. It can do nothing else. And then there's a conscious thing that has choices, free will choices. It can do things or not do things based on its own will of what it wants to do. Now, you can make a computer that is algorithmic. You can make a computer like that that is totally algorithmic, has no consciousness, but it can emulate consciousness. We call that an expert system. Now, expert systems can act like they're conscious depending on how extensive their information is about appropriate responses and how much memory and speed they have for accessing those things. So if you could put into a computer every possible response to every possible stimulation, then that expert system could act like it was conscious. You could have conversations with it, you could ask it questions, you could discuss poetry, you could do whatever you want and it would have programmed in it the appropriate response. So it would just have to be clever enough to know what you were asking, come up with the right response and push that out. Now, that would be extremely hard to do because such a database would be probably impossible to put together because our reality is so complexly interactive that coming up with every possible response to every possible thing is impossible. So you probably never have an expert system that you couldn't tell that it wasn't conscious if you lived with it long enough and if you were clever enough to figure it out. But you could have an expert system that acted very much like a human, did a lot of things that humans would do. If you gave it a body with legs that it could walk around in and arms and a mouth where it could speak and so on, you might have a hard time. You may have to live with it for a year before you found out it was an expert system, but you could eventually find out because it's too much to ask it to have an appropriate response for everything and for its responses to be varied enough that it didn't sound like it was canned. So that'd be hard to do but not impossible. Theoretically, you could have an expert system that was very difficult to tell that it wasn't conscious. It'd be very hard.

SPEAKER_B

So  even if we build that, that basically still would not be conscious. And if I understand correctly, the reason is that there is no uncertainty in the choices that would enable the free will, right?

XXXTom CampbellXXX

It's  not aware is its thing. It has choices. It may have you say something, may find that it has ten appropriate responses and it may have to pick one. So it may have choice enough to even qualify as a free will choice. There'd be little algorithms in there maybe to help it or maybe it'd be a random number generator that would just pick one of the ten. It would have ways to do that but it would not be aware. It's just a machine trying to put out data that's appropriate to what it takes in and it's just a machine that's very good at saying oh, I got this in so I'll put that out. There's no awareness involved in it at all. So that's not conscious. So you could have a computer that appears to be conscious, maybe even one that most people would never even be able to tell that it was not conscious, theoretically, but it wouldn't be conscious, you see. So that's an expert system. Expert systems can be very clever and no doubt expert systems will have conversation with you, but it's usually limited because their data that describes the appropriate response is limited and their ability to understand what you're asking is limited and it's limited just by technology. It's not theoretically limited. If you could have a database of infinite size and a speed that could search a database of infinite size in real time then it would be possible. But it's not practical so it'll never actually be able to be done. It's just you can't have an infinite database. So it could be very good though, that the average person would not be able to tell that it wasn't conscious. Could be that good eventually, what, 100 years from now as our computers get faster and faster and faster and we go beyond silicon into other things that allow more and more efficiency. So you could get to the point that it would be very human like and could do a lot of the same things. It could also maybe do the national electrical grid very well. So an expert system can do a lot of the same things but it's not conscious. It's just a machine that is chugging through the logic programmed into it to come out with a response that seems reasonable. That's it. So that's an expert system. But now a conscious computer is going to be different than that. It's going to have an individuated unit of consciousness logged on as the player of an avatar that is a computer. You see that's different and it's going to have all the attributes that any consciousness has. It's going to have uncertainty. You ask it the same question twice and you may get two different answers. It's going to be inconsistent sometimes. It will sometimes get confused. An expert system will probably never show that it's confused. Even if it is, it'll just give you the best answer it has. So it'll have all the attributes of consciousness. But it will be able to make choices and it will be aware. It's aware not because awareness was programmed in, but it's aware because an individuated unit of consciousness logged on as its player. The consciousness is the player. The computer in this case is the avatar, just like the consciousness is the player and the human is the avatar. So they're just two completely different routes to take. Now, you won't have to worry about the expert system taking over the world because obviously the programmer tells it exactly what its range of choices is. If taking over the world is not one of its choices, it can't do that. You see. Now a conscious computer is not like that. A conscious computer makes its own comes to its own choices. So it's a lot more subtle process and it carries a lot more risk, but it's probably a lot easier to do. Making this expert system so good that it's hard to tell from a human is a very hard thing to do.

SPEAKER_B

Yeah,  I think you would basically have to build all the knowledge into the computer as opposed to letting the consciousness itself learn the information. Right. Yeah.

XXXTom CampbellXXX

And  thinking of building everything that could possibly happen in a database, every question, every nuance, everything that might happen in life, it would have the appropriate response to it. That's pretty much impossible. So we'll use those expert systems and we'll make them very good. But we'll always run into limitations of size and speed and cleverness of the programmer. Now, the programmers are going to have to be very clever to make all this software that would allow an expert system to act like a human, but in very limited ways. If you have a job or a thing that has limited functions to it, then yes, you could have an expert system do things. You could have an expert system do many things I guess the humans do, because a lot of work the humans do does not call for a lot of creativity or interpretation. It's pretty straightforward. Now, our computers, my laptop here is kind of an expert system. In some ways I misspell a word, it draws a little red line under it or it automatically just re puts the word in spelled right. Well, that's an expert system. It sees a problem, it goes and fixes it. It's not very intrusive. I wouldn't confuse it with there's a little human inside my computer fixing my spelling. But we have expert systems now that work for us all the time. The little vacuum cleaner runs around in my house. That's a little robot. That's an expert system. It's got a lot of algorithms in there and it's got a bunch of sensors and if it senses it's coming up to a stair, it sees the suddenly there's no floor under it and it stops, doesn't go there and fall down the stairs. It backs up and goes some other direction. It gets stuck in a corner. It has algorithms that help it get free, gets stuck under a chair, it knows to back up, move right, that doesn't work, back up, move left, go forward, move left, then right, and it works its way out. But it's all algorithms. So expert systems can do things like vacuum your floors pretty efficiently. It's actually pretty good. I had one of those when they first came out and it was horrible. It didn't do very well at all. And it required special other equipment that you had to put little light beams where you didn't want it to go and things like that. But now they're much smarter. The expert systems has gotten smart enough that you just program the thing in certain time of day, it'll wake up, go vacuum your floors in certain spaces that you tell it to do, leave other spaces alone and go back, put itself away and put itself back on its charger again. So it basically can handle all the functions. No human needs to do anything other than buy it and plug it in and then program it, tell it what you want it to do. We've got expert systems that help us do things. Now a lot of manufacturing is done with expert systems. When you go down the line where you have expert systems who do assembly and manufacturing and making parts and a lot of factory work is automated now. And they're all really just expert systems. They're experts at doing the small task that they're expected to do and they don't have to take coffee breaks, they don't go to the bathroom. They work 24 hours a day and they never complain. So they become a way that we can manufacture things less expensively, they're more efficient, take our conscious humans and train them to do more creative things instead of things that expert systems can do. So that's kind of the expert system and it's very different than a conscious system. It's an expert at a particular task. And the more generalized that task is, the more difficulty it is to make it an expert. The simpler and more straightforward that task is, the easier it is to become an expert. So being a human being is a very complex task. Interacting with others and that sort of thing is a hugely complex task. So they're not really very good at doing that yet. Probably never will be really good at doing that. I think they will pretty much always be obvious that they're an expert system. It just would cost too much. The thing would be so prohibitive in its cost if it actually could trick people into thinking it was human. But then that's just now. Who knows what the technology will be like 100 or 1000 years from now. That speed and memory may not be a problem. Hard to say, but that's a basic difference.

SPEAKER_B

I  see. So if I understand correctly, it's not really uncertainty, but more like the awareness that is required for conscious choice making, right?

XXXTom CampbellXXX

Yes,  it's the awareness. Now, uncertainty is an important part of it because if it's algorithmic, it's certain you know exactly what it's going to do. Again, stimulus response. I give it this input, it does that output. So there's no uncertainty with consciousness. There's always some uncertainty about what it'll do. You can ask the same human the same question a week apart and you'll probably get two different answers. You certainly will get different words, but it'll be very similar. But it won't be the same. So if I ask you today, if I give you a question, you give me an answer today. A week later I give you the same question. I won't get exactly the same words in the same order. I'll get something else. I'll get something very similar because you still have that same opinion, but you'll express it differently. And even if it's not a week, even if it's only an hour or a minute, it's likely you're going to express it differently. It just comes out however it does. So that's the way it is with consciousness. There's usually uncertainty involved with consciousness, consciousness is not algorithmic. It's not certain what it'll do or what it'll come up with. It changes from time to time. It has these free will choices. Well, I could say it this way or I could say it that way, and it just picks one as it goes. Because you're in conversation, you have to pick a word. So you pick a sentence and a word and that's the way you go. And if you do it a day later, you pick different words and say different things. There is uncertainty that is in and around consciousness. You can't have a certain result. The only way to have a certain result is if it's driven by algorithms. Then you will get a certain result. Then it's a machine, it's not conscious.

SPEAKER_B

So  the output itself is the one that needs to be uncertain.

XXXTom CampbellXXX

Yeah,  well, the whole process, the output is what is uncertain. Yes, you can give it certain input, type an H. My certain input is I punch the H key and if I've just got an unconscious computer here, its certain output will be to put an H on my screen. Now, the computer could have some of its components fail or something like that. That would cause an uncertainty. But that's different. We're talking about a computer and everything's working or whatever. It'll do exactly what it's supposed to do and it can't do anything else. So there's certainty in that because it's algorithmic. With consciousness, conscious has free will choice. It's not so likely just to repeat itself. Exactly. It's got uncertainty about what it does. Okay, I got 20 choices. One time I choose number seven, and the next time I choose number 18. Why? I don't know. It's the way it came out, the way I thought of it. Consciousness isn't required to repeat itself or to be consistent. In fact, it's typically not consistent if you are with it. If you interact with it long enough, you'll find that it isn't consistent always.

SPEAKER_B

Yeah,  I think in your model you somewhere said that this whole choice making is basically intent based and that it somehow modifies the future probabilities.

XXXTom CampbellXXX

That'S  true. You see, a conscious thing is always learning, so it always is getting new experience. And that new experience modifies what it is, what it knows. So it learns something. Now it knows that, and it didn't know it before, so it's different now. It's a different thing. So all of the time, all the experience it sees and hears and smells and all of that stuff produces knowledge, produces understanding. And that awareness is sorting through all the facts, have come in through its sensors and understands. It sorts, it finds connections between, it does, all that sort of thing. You are not the same consciousness from day to day or minute to minute. It's all in flux. And when you have a neural net, that's why neural nets can be a basis, can be an avatar, because they work the same way. Every time they learn something, every time they get new experience, it changes what they are, it changes how they'll respond. See, it's the same thing. They get a new experience. And now all those coefficients in there shuffle around a little bit and they're different. Now they learn. An expert system doesn't necessarily do that. Now an expert system could learn, too. Expert systems can learn. My computer here will learn. My laptop here will learn about choices that I make. I typically do these kinds of things. So it'll set me up with those things first because it's got a little memory that says, tom usually uses these words or does these things. So when it boots up, it may give me things that it says are typical for me to have. So it can learn. So expert systems can learn. But that just means their databases are broader. They have more data they can pick from, so they can help develop their databases as they go. But they're still stuck with their algorithms. They're going to sort that new data exactly the same way.

SPEAKER_B

Okay,  I see. I think this basically covers all my questions for this session. Tom, I appreciate you taking the time to answer all of these complicated questions.